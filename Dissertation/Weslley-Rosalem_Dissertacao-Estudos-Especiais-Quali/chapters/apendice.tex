\chapter{pre-processamento.R}

\begin{verbatim}
# @author: thiago<at>fatecourinhos.edu.br
# @since: 2020

# Acessa o diretorio onde se encontra o Dataset
setwd("...\\Mestrado\\Datasets\\MachineLearningCVE")

# Carrega o Dataset
dataset <- read.csv("Wednesday-workingHours.pcap_ISCX.csv", 
                   header=TRUE,stringsAsFactors = TRUE)

# Conversão de todos os campos para valores numéricos (exceto Labels)
input <- data.matrix(dataset[,1:78])

# Normalização dos valores para o intervalo 0 ... 1
input_norm <- t(apply(input, 1,
               function(x)(x-min(x))/(max(x)-min(x))))

# Adiciona as Labels ao dataset_preprocessado
# obtem as Labels originais
labels <- dataset[,79] 

# Cria o 'dataset_preprocessado' com os valores normalizados
# à esquerda e as Labels à direita
dataset_preprocessado <- merge(input_norm, labels,
                              by = "row.names", all = TRUE)

# Remove coluna 'row.names' por não ser necessária
dataset_preprocessado <- dataset_preprocessado[,2:80]

# Renomeia a coluna de 'y' para 'Label'
names(dataset_preprocessado)[names(dataset_preprocessado) ==
                            'y'] <- 'Label'

# Remove valores NaN
dataset_preprocessado <- dataset_preprocessado[complete.cases(
                         dataset_preprocessado),]

# Salvando em CSV
write.csv(dataset_preprocessado,"dataset_preprocessado.csv",
         row.names = FALSE)

\end{verbatim}

\chapter{tune\_hyperparametros.py}
\begin{verbatim}
    
#!/usr/bin/env python3
# -*- coding: utf-8 -*-

# @author: thiago<at>fatecourinhos.edu.br
# @since: 2020



# Pandas
import pandas as pd

# NumPy
import numpy as np
from numpy import array

# Sci-kit Learn
from sklearn import model_selection
from sklearn.model_selection import cross_val_predict, GridSearchCV

from sklearn.neighbors import KNeighborsClassifier
from sklearn.tree import DecisionTreeClassifier
from sklearn.neural_network import MLPClassifier
from sklearn.svm import SVC

from sklearn.metrics import *

# MLXtend (Stacking)
from mlxtend.classifier import StackingClassifier

ds = array(pd.read_csv("../../full_datasets/1_full.csv"))

X = ds[:, 0:77] # X == features
y = ds[:, 78]   # y == rótulos




####################################################################
#                               KNN                                #
####################################################################
#
# > TUNE
#
grid_params = {
    'n_neighbors': [1,3,5,7,9,11,13,15,17,19,21],
    'weights': ['uniform', 'distance'],
    'metric': ['euclidean','manhattan'],

    }

gs = GridSearchCV(
    KNeighborsClassifier(),
    grid_params,
    verbose = 1,
    cv = 10,
    n_jobs = -1,
    error_score = 'raise'
    )

gs_results = gs.fit(X, y)
print(gs_results.best_params_)



####################################################################
#                               MLP                                #
####################################################################
#
# > TUNE

parameters = {'solver': ['lbfgs', 'adam'],
              'alpha': 10.0 ** -np.arange(1, 4),
              'hidden_layer_sizes':np.arange(10, 15),
              'random_state':[0,1,2,3,4,5,6,7,8,9]}

clf = GridSearchCV(MLPClassifier(max_iter=10000), parameters, n_jobs=-1, 
                  cv=3, verbose = 1)
clf.fit(X, y)
print(clf.best_params_)
print(clf.score(X, y))




####################################################################
#                                DT                                #
####################################################################
#
# > TUNE
#
parameters={'min_samples_split' : range(10,500,20),'max_depth': range(1,20,2)}
clf_tree=DecisionTreeClassifier()
clf=GridSearchCV(clf_tree,parameters, cv=10, verbose=1)
clf.fit(X,y)
print(clf.best_params_)
print(clf.score(X, y))





####################################################################
#                          SVM RBF                                 #
####################################################################
#
# > TUNE
#
Cs = [0.01, 0.1, 1]
gammas = [0.01, 0.1, 1]
param_grid = {'C': Cs, 'gamma' : gammas}
grid_search = GridSearchCV(SVC(kernel='rbf'), param_grid, cv=3, verbose=1)
grid_search.fit(X, y)
print(grid_search.best_params_)




\end{verbatim}
\chapter{diversidade.py}
\label{apendice_diversidade}

\begin{verbatim}
#!/usr/bin/env python3
# -*- coding: utf-8 -*-

# @author: thiago<at>fatecourinhos.edu.br
# @since: 2020

# -> omitido import das bibliotecas por espaço 
    
def agreementMatrix(clfA, clfB, realLabels):
    a=0
    b=0
    c=0
    d=0

    for i in range(np.size(y)):
        yLabel = realLabels[i]
        aLabel = clfA[i]
        bLabel = clfB[i]

    #    print("*******")
    #    print(yLabel)
    #    print(aLabel)
    #    print(bLabel)

        if aLabel == bLabel:
            if aLabel == yLabel: #a
                a = a+1

        if aLabel == yLabel:
            if bLabel != yLabel: #b
                b = b+1

        if bLabel == yLabel:
            if aLabel != yLabel: #c
                c = c+1

        if aLabel != yLabel:
            if bLabel == aLabel: #d
                d = d+1

    agreementMatrix = (b+c)/(a+b+c+d)
    print(agreementMatrix)

agreementMatrix(clf1_pred, clf1_pred, y)

import itertools
modelos=['clf1_pred','clf2_pred','clf3_pred', 'clf4_pred']
combinacoes = np.array(list(itertools.combinations(modelos, 2)))

for ii in range(0,int(combinacoes.size/2)):
    a=combinacoes[ii,0]
    b=combinacoes[ii,1]
    cmd=str("agreementMatrix(%s, %s, y)" % (a, b))
    print("***********************************************************")

    print("%s,%s\b\b" % (a,b))
    exec(cmd)


\end{verbatim}

\chapter{exaustao.py}



\begin{verbatim}
#!/usr/bin/env python3
# -*- coding: utf-8 -*-

# @author: thiago<at>fatecourinhos.edu.br
# @since: 2020

# -> omitido import das bibliotecas por espaço 

os.popen('echo "******* Exaustao -----> $(date)" >> execution_2.log')
print("Exaustao start --->", time.asctime())

print("layer1,layer2,acuracia,auc,precision,recall,f1,
     trueP,falseP,falseN,trueN")

# STACKING clf1+clf2,clf1
os.popen('echo "******* xxxxxxxxxxxxxxxx -----> $(date)" >> execution_2.log')
stack = StackingClassifier([clf1, clf2], meta_classifier=clf1)
stack_pred = cross_val_predict(stack, X, y, cv=10)
conf_stack = confusion_matrix(y, stack_pred)

print("clf1+clf2,clf1,%f,%f,%f,%f,%f,%f,%f,%f,%f" %
     (accuracy_score(y, stack_pred),roc_auc_score(y, stack_pred),precision_score(y, stack_pred),recall_score(y, stack_pred),f1_score(y, stack_pred),conf_stack[0,0],conf_stack[0,1],
     conf_stack[1,0],conf_stack[1,1]))

# ... código continua para todas as possíveis combinações 
print("Exaustao stop --->", time.asctime())\end{verbatim}