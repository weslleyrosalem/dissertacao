{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "46b8d320",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: mlflow in ./.venv/lib/python3.11/site-packages (2.22.0)\n",
      "Requirement already satisfied: joblib in ./.venv/lib/python3.11/site-packages (1.4.2)\n",
      "Requirement already satisfied: mlflow-skinny==2.22.0 in ./.venv/lib/python3.11/site-packages (from mlflow) (2.22.0)\n",
      "Requirement already satisfied: Flask<4 in ./.venv/lib/python3.11/site-packages (from mlflow) (3.1.0)\n",
      "Requirement already satisfied: Jinja2<4,>=2.11 in ./.venv/lib/python3.11/site-packages (from mlflow) (3.1.6)\n",
      "Requirement already satisfied: alembic!=1.10.0,<2 in ./.venv/lib/python3.11/site-packages (from mlflow) (1.15.2)\n",
      "Requirement already satisfied: docker<8,>=4.0.0 in ./.venv/lib/python3.11/site-packages (from mlflow) (7.1.0)\n",
      "Requirement already satisfied: graphene<4 in ./.venv/lib/python3.11/site-packages (from mlflow) (3.4.3)\n",
      "Requirement already satisfied: gunicorn<24 in ./.venv/lib/python3.11/site-packages (from mlflow) (23.0.0)\n",
      "Requirement already satisfied: markdown<4,>=3.3 in ./.venv/lib/python3.11/site-packages (from mlflow) (3.8)\n",
      "Requirement already satisfied: matplotlib<4 in ./.venv/lib/python3.11/site-packages (from mlflow) (3.10.1)\n",
      "Requirement already satisfied: numpy<3 in ./.venv/lib/python3.11/site-packages (from mlflow) (2.2.5)\n",
      "Requirement already satisfied: pandas<3 in ./.venv/lib/python3.11/site-packages (from mlflow) (2.2.3)\n",
      "Requirement already satisfied: pyarrow<20,>=4.0.0 in ./.venv/lib/python3.11/site-packages (from mlflow) (19.0.1)\n",
      "Requirement already satisfied: scikit-learn<2 in ./.venv/lib/python3.11/site-packages (from mlflow) (1.6.1)\n",
      "Requirement already satisfied: scipy<2 in ./.venv/lib/python3.11/site-packages (from mlflow) (1.15.2)\n",
      "Requirement already satisfied: sqlalchemy<3,>=1.4.0 in ./.venv/lib/python3.11/site-packages (from mlflow) (2.0.40)\n",
      "Requirement already satisfied: cachetools<6,>=5.0.0 in ./.venv/lib/python3.11/site-packages (from mlflow-skinny==2.22.0->mlflow) (5.5.2)\n",
      "Requirement already satisfied: click<9,>=7.0 in ./.venv/lib/python3.11/site-packages (from mlflow-skinny==2.22.0->mlflow) (8.1.8)\n",
      "Requirement already satisfied: cloudpickle<4 in ./.venv/lib/python3.11/site-packages (from mlflow-skinny==2.22.0->mlflow) (3.1.1)\n",
      "Requirement already satisfied: databricks-sdk<1,>=0.20.0 in ./.venv/lib/python3.11/site-packages (from mlflow-skinny==2.22.0->mlflow) (0.52.0)\n",
      "Requirement already satisfied: fastapi<1 in ./.venv/lib/python3.11/site-packages (from mlflow-skinny==2.22.0->mlflow) (0.115.12)\n",
      "Requirement already satisfied: gitpython<4,>=3.1.9 in ./.venv/lib/python3.11/site-packages (from mlflow-skinny==2.22.0->mlflow) (3.1.44)\n",
      "Requirement already satisfied: importlib_metadata!=4.7.0,<9,>=3.7.0 in ./.venv/lib/python3.11/site-packages (from mlflow-skinny==2.22.0->mlflow) (8.6.1)\n",
      "Requirement already satisfied: opentelemetry-api<3,>=1.9.0 in ./.venv/lib/python3.11/site-packages (from mlflow-skinny==2.22.0->mlflow) (1.32.1)\n",
      "Requirement already satisfied: opentelemetry-sdk<3,>=1.9.0 in ./.venv/lib/python3.11/site-packages (from mlflow-skinny==2.22.0->mlflow) (1.32.1)\n",
      "Requirement already satisfied: packaging<25 in ./.venv/lib/python3.11/site-packages (from mlflow-skinny==2.22.0->mlflow) (24.2)\n",
      "Requirement already satisfied: protobuf<7,>=3.12.0 in ./.venv/lib/python3.11/site-packages (from mlflow-skinny==2.22.0->mlflow) (6.30.2)\n",
      "Requirement already satisfied: pydantic<3,>=1.10.8 in ./.venv/lib/python3.11/site-packages (from mlflow-skinny==2.22.0->mlflow) (2.11.4)\n",
      "Requirement already satisfied: pyyaml<7,>=5.1 in ./.venv/lib/python3.11/site-packages (from mlflow-skinny==2.22.0->mlflow) (6.0.2)\n",
      "Requirement already satisfied: requests<3,>=2.17.3 in ./.venv/lib/python3.11/site-packages (from mlflow-skinny==2.22.0->mlflow) (2.32.3)\n",
      "Requirement already satisfied: sqlparse<1,>=0.4.0 in ./.venv/lib/python3.11/site-packages (from mlflow-skinny==2.22.0->mlflow) (0.5.3)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.0.0 in ./.venv/lib/python3.11/site-packages (from mlflow-skinny==2.22.0->mlflow) (4.13.2)\n",
      "Requirement already satisfied: uvicorn<1 in ./.venv/lib/python3.11/site-packages (from mlflow-skinny==2.22.0->mlflow) (0.34.2)\n",
      "Requirement already satisfied: Mako in ./.venv/lib/python3.11/site-packages (from alembic!=1.10.0,<2->mlflow) (1.3.10)\n",
      "Requirement already satisfied: urllib3>=1.26.0 in ./.venv/lib/python3.11/site-packages (from docker<8,>=4.0.0->mlflow) (2.4.0)\n",
      "Requirement already satisfied: Werkzeug>=3.1 in ./.venv/lib/python3.11/site-packages (from Flask<4->mlflow) (3.1.3)\n",
      "Requirement already satisfied: itsdangerous>=2.2 in ./.venv/lib/python3.11/site-packages (from Flask<4->mlflow) (2.2.0)\n",
      "Requirement already satisfied: blinker>=1.9 in ./.venv/lib/python3.11/site-packages (from Flask<4->mlflow) (1.9.0)\n",
      "Requirement already satisfied: graphql-core<3.3,>=3.1 in ./.venv/lib/python3.11/site-packages (from graphene<4->mlflow) (3.2.6)\n",
      "Requirement already satisfied: graphql-relay<3.3,>=3.1 in ./.venv/lib/python3.11/site-packages (from graphene<4->mlflow) (3.2.0)\n",
      "Requirement already satisfied: python-dateutil<3,>=2.7.0 in ./.venv/lib/python3.11/site-packages (from graphene<4->mlflow) (2.9.0.post0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in ./.venv/lib/python3.11/site-packages (from Jinja2<4,>=2.11->mlflow) (3.0.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in ./.venv/lib/python3.11/site-packages (from matplotlib<4->mlflow) (1.3.2)\n",
      "Requirement already satisfied: cycler>=0.10 in ./.venv/lib/python3.11/site-packages (from matplotlib<4->mlflow) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in ./.venv/lib/python3.11/site-packages (from matplotlib<4->mlflow) (4.57.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in ./.venv/lib/python3.11/site-packages (from matplotlib<4->mlflow) (1.4.8)\n",
      "Requirement already satisfied: pillow>=8 in ./.venv/lib/python3.11/site-packages (from matplotlib<4->mlflow) (11.2.1)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in ./.venv/lib/python3.11/site-packages (from matplotlib<4->mlflow) (3.2.3)\n",
      "Requirement already satisfied: pytz>=2020.1 in ./.venv/lib/python3.11/site-packages (from pandas<3->mlflow) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in ./.venv/lib/python3.11/site-packages (from pandas<3->mlflow) (2025.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in ./.venv/lib/python3.11/site-packages (from scikit-learn<2->mlflow) (3.6.0)\n",
      "Requirement already satisfied: google-auth~=2.0 in ./.venv/lib/python3.11/site-packages (from databricks-sdk<1,>=0.20.0->mlflow-skinny==2.22.0->mlflow) (2.39.0)\n",
      "Requirement already satisfied: starlette<0.47.0,>=0.40.0 in ./.venv/lib/python3.11/site-packages (from fastapi<1->mlflow-skinny==2.22.0->mlflow) (0.46.2)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in ./.venv/lib/python3.11/site-packages (from gitpython<4,>=3.1.9->mlflow-skinny==2.22.0->mlflow) (4.0.12)\n",
      "Requirement already satisfied: zipp>=3.20 in ./.venv/lib/python3.11/site-packages (from importlib_metadata!=4.7.0,<9,>=3.7.0->mlflow-skinny==2.22.0->mlflow) (3.21.0)\n",
      "Requirement already satisfied: deprecated>=1.2.6 in ./.venv/lib/python3.11/site-packages (from opentelemetry-api<3,>=1.9.0->mlflow-skinny==2.22.0->mlflow) (1.2.18)\n",
      "Requirement already satisfied: opentelemetry-semantic-conventions==0.53b1 in ./.venv/lib/python3.11/site-packages (from opentelemetry-sdk<3,>=1.9.0->mlflow-skinny==2.22.0->mlflow) (0.53b1)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in ./.venv/lib/python3.11/site-packages (from pydantic<3,>=1.10.8->mlflow-skinny==2.22.0->mlflow) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in ./.venv/lib/python3.11/site-packages (from pydantic<3,>=1.10.8->mlflow-skinny==2.22.0->mlflow) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in ./.venv/lib/python3.11/site-packages (from pydantic<3,>=1.10.8->mlflow-skinny==2.22.0->mlflow) (0.4.0)\n",
      "Requirement already satisfied: six>=1.5 in ./.venv/lib/python3.11/site-packages (from python-dateutil<3,>=2.7.0->graphene<4->mlflow) (1.17.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./.venv/lib/python3.11/site-packages (from requests<3,>=2.17.3->mlflow-skinny==2.22.0->mlflow) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./.venv/lib/python3.11/site-packages (from requests<3,>=2.17.3->mlflow-skinny==2.22.0->mlflow) (3.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./.venv/lib/python3.11/site-packages (from requests<3,>=2.17.3->mlflow-skinny==2.22.0->mlflow) (2025.4.26)\n",
      "Requirement already satisfied: h11>=0.8 in ./.venv/lib/python3.11/site-packages (from uvicorn<1->mlflow-skinny==2.22.0->mlflow) (0.16.0)\n",
      "Requirement already satisfied: wrapt<2,>=1.10 in ./.venv/lib/python3.11/site-packages (from deprecated>=1.2.6->opentelemetry-api<3,>=1.9.0->mlflow-skinny==2.22.0->mlflow) (1.17.2)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in ./.venv/lib/python3.11/site-packages (from gitdb<5,>=4.0.1->gitpython<4,>=3.1.9->mlflow-skinny==2.22.0->mlflow) (5.0.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in ./.venv/lib/python3.11/site-packages (from google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==2.22.0->mlflow) (0.4.2)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in ./.venv/lib/python3.11/site-packages (from google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==2.22.0->mlflow) (4.9.1)\n",
      "Requirement already satisfied: anyio<5,>=3.6.2 in ./.venv/lib/python3.11/site-packages (from starlette<0.47.0,>=0.40.0->fastapi<1->mlflow-skinny==2.22.0->mlflow) (4.9.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in ./.venv/lib/python3.11/site-packages (from anyio<5,>=3.6.2->starlette<0.47.0,>=0.40.0->fastapi<1->mlflow-skinny==2.22.0->mlflow) (1.3.1)\n",
      "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in ./.venv/lib/python3.11/site-packages (from pyasn1-modules>=0.2.1->google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==2.22.0->mlflow) (0.6.1)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install mlflow joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afaafbbb",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 260\u001b[39m\n\u001b[32m    250\u001b[39m bounds = [\n\u001b[32m    251\u001b[39m     [-\u001b[32m3.3\u001b[39m, -\u001b[32m2.7\u001b[39m],  \u001b[38;5;66;03m# log10(learning_rate): [0.0005, 0.002]\u001b[39;00m\n\u001b[32m    252\u001b[39m     [\u001b[32m0\u001b[39m, \u001b[32m1\u001b[39m],        \u001b[38;5;66;03m# num_layers (mapeado para [2, 3])\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    256\u001b[39m     [\u001b[32m0.0\u001b[39m, \u001b[32m0.1\u001b[39m]     \u001b[38;5;66;03m# weight_decay\u001b[39;00m\n\u001b[32m    257\u001b[39m ]\n\u001b[32m    259\u001b[39m mrfo = MRFO(objective_function, bounds, n_mantas=\u001b[32m30\u001b[39m, max_iter=\u001b[32m20\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m260\u001b[39m best_position, best_fitness = \u001b[43mmrfo\u001b[49m\u001b[43m.\u001b[49m\u001b[43moptimize\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    262\u001b[39m \u001b[38;5;66;03m# Mapear a melhor posição para hiperparâmetros\u001b[39;00m\n\u001b[32m    263\u001b[39m best_lr = \u001b[32m10\u001b[39m ** best_position[\u001b[32m0\u001b[39m]\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 193\u001b[39m, in \u001b[36mMRFO.optimize\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    190\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m.max_iter):\n\u001b[32m    191\u001b[39m     \u001b[38;5;66;03m# Avaliar fitness de todas as mantas\u001b[39;00m\n\u001b[32m    192\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m.n_mantas):\n\u001b[32m--> \u001b[39m\u001b[32m193\u001b[39m         \u001b[38;5;28mself\u001b[39m.fitness[i] = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mobjective_func\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mpositions\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    194\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.fitness[i] < \u001b[38;5;28mself\u001b[39m.best_fitness:\n\u001b[32m    195\u001b[39m             \u001b[38;5;28mself\u001b[39m.best_fitness = \u001b[38;5;28mself\u001b[39m.fitness[i]\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 241\u001b[39m, in \u001b[36mobjective_function\u001b[39m\u001b[34m(params)\u001b[39m\n\u001b[32m    238\u001b[39m wd = params[\u001b[32m5\u001b[39m]  \u001b[38;5;66;03m# weight_decay\u001b[39;00m\n\u001b[32m    240\u001b[39m \u001b[38;5;66;03m# Executar repetições em paralelo\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m241\u001b[39m results = \u001b[43mParallel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m=\u001b[49m\u001b[43m-\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    242\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_and_evaluate\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnh\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwd\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m_\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mrange\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mn_repetitions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    243\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    245\u001b[39m mae_list = [result[\u001b[32m0\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m result \u001b[38;5;129;01min\u001b[39;00m results]\n\u001b[32m    246\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m np.mean(mae_list)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/0x0-Coding/GitHub/dissertacao/Experiments/src/2025/.venv/lib/python3.11/site-packages/joblib/parallel.py:2007\u001b[39m, in \u001b[36mParallel.__call__\u001b[39m\u001b[34m(self, iterable)\u001b[39m\n\u001b[32m   2001\u001b[39m \u001b[38;5;66;03m# The first item from the output is blank, but it makes the interpreter\u001b[39;00m\n\u001b[32m   2002\u001b[39m \u001b[38;5;66;03m# progress until it enters the Try/Except block of the generator and\u001b[39;00m\n\u001b[32m   2003\u001b[39m \u001b[38;5;66;03m# reaches the first `yield` statement. This starts the asynchronous\u001b[39;00m\n\u001b[32m   2004\u001b[39m \u001b[38;5;66;03m# dispatch of the tasks to the workers.\u001b[39;00m\n\u001b[32m   2005\u001b[39m \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[32m-> \u001b[39m\u001b[32m2007\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.return_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/0x0-Coding/GitHub/dissertacao/Experiments/src/2025/.venv/lib/python3.11/site-packages/joblib/parallel.py:1650\u001b[39m, in \u001b[36mParallel._get_outputs\u001b[39m\u001b[34m(self, iterator, pre_dispatch)\u001b[39m\n\u001b[32m   1647\u001b[39m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[32m   1649\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backend.retrieval_context():\n\u001b[32m-> \u001b[39m\u001b[32m1650\u001b[39m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m._retrieve()\n\u001b[32m   1652\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mGeneratorExit\u001b[39;00m:\n\u001b[32m   1653\u001b[39m     \u001b[38;5;66;03m# The generator has been garbage collected before being fully\u001b[39;00m\n\u001b[32m   1654\u001b[39m     \u001b[38;5;66;03m# consumed. This aborts the remaining tasks if possible and warn\u001b[39;00m\n\u001b[32m   1655\u001b[39m     \u001b[38;5;66;03m# the user if necessary.\u001b[39;00m\n\u001b[32m   1656\u001b[39m     \u001b[38;5;28mself\u001b[39m._exception = \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/0x0-Coding/GitHub/dissertacao/Experiments/src/2025/.venv/lib/python3.11/site-packages/joblib/parallel.py:1762\u001b[39m, in \u001b[36mParallel._retrieve\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If the next job is not ready for retrieval yet, we just wait for\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# async callbacks to progress.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m ((\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m._jobs) == \u001b[32m0\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m\n\u001b[32m   1760\u001b[39m     (\u001b[38;5;28mself\u001b[39m._jobs[\u001b[32m0\u001b[39m].get_status(\n\u001b[32m   1761\u001b[39m         timeout=\u001b[38;5;28mself\u001b[39m.timeout) == TASK_PENDING)):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     time.sleep(\u001b[32m0.01\u001b[39m)\n\u001b[32m   1763\u001b[39m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[32m   1765\u001b[39m \u001b[38;5;66;03m# We need to be careful: the job list can be filling up as\u001b[39;00m\n\u001b[32m   1766\u001b[39m \u001b[38;5;66;03m# we empty it and Python list are not thread-safe by\u001b[39;00m\n\u001b[32m   1767\u001b[39m \u001b[38;5;66;03m# default hence the use of the lock\u001b[39;00m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, mean_absolute_percentage_error\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "import mlflow\n",
    "import mlflow.pytorch\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "# Configurar MLflow\n",
    "mlflow.set_tracking_uri(\"http://localhost:5001\")\n",
    "mlflow.set_experiment(\"Prometheus_Transformer_MRFO_Experiment\")\n",
    "\n",
    "# Definindo constantes\n",
    "DATA_DIR = \"../../data/\"\n",
    "FILE_PATH = os.path.join(DATA_DIR, 'ts.pkl')\n",
    "SEQ_LENGTH = 48\n",
    "MB = 1_048_576\n",
    "\n",
    "# 1. Carregar e reamostrar os dados\n",
    "df = pd.read_pickle(FILE_PATH)\n",
    "ts = df['value'].astype(float).resample('15min').mean().dropna()\n",
    "dates = ts.index\n",
    "\n",
    "# 2. Dividir os dados: 60% treino, 20% validação, 20% teste\n",
    "train_size = int(0.6 * len(ts))\n",
    "val_size = int(0.2 * len(ts))\n",
    "train = ts[:train_size]\n",
    "val = ts[train_size:train_size + val_size]\n",
    "test = ts[train_size + val_size:]\n",
    "\n",
    "# 3. Escalonar os dados\n",
    "scaler = StandardScaler()\n",
    "train_scaled = scaler.fit_transform(train.values.reshape(-1, 1))\n",
    "val_scaled = scaler.transform(val.values.reshape(-1, 1))\n",
    "test_scaled = scaler.transform(test.values.reshape(-1, 1))\n",
    "\n",
    "# 4. Criar sequências\n",
    "def create_sequences(data, dates, seq_length):\n",
    "    X, y, y_dates = [], [], []\n",
    "    for i in range(len(data) - seq_length):\n",
    "        X.append(data[i:i + seq_length])\n",
    "        y.append(data[i + seq_length])\n",
    "        y_dates.append(dates[i + seq_length])\n",
    "    return np.array(X), np.array(y), np.array(y_dates)\n",
    "\n",
    "X_train, y_train, y_dates_train = create_sequences(train_scaled, dates[:train_size], SEQ_LENGTH)\n",
    "X_val, y_val, y_dates_val = create_sequences(val_scaled, dates[train_size:train_size + val_size], SEQ_LENGTH)\n",
    "X_test, y_test, y_dates_test = create_sequences(test_scaled, dates[train_size + val_size:], SEQ_LENGTH)\n",
    "\n",
    "# 5. Ajustar dimensões para o modelo Transformer\n",
    "d_model = 128\n",
    "X_train = np.repeat(X_train, d_model, axis=2)\n",
    "X_val = np.repeat(X_val, d_model, axis=2)\n",
    "X_test = np.repeat(X_test, d_model, axis=2)\n",
    "\n",
    "# 6. Converter para tensores PyTorch\n",
    "X_train = torch.tensor(X_train, dtype=torch.float32)\n",
    "y_train = torch.tensor(y_train, dtype=torch.float32)\n",
    "X_val = torch.tensor(X_val, dtype=torch.float32)\n",
    "y_val = torch.tensor(y_val, dtype=torch.float32)\n",
    "X_test = torch.tensor(X_test, dtype=torch.float32)\n",
    "y_test = torch.tensor(y_test, dtype=torch.float32)\n",
    "\n",
    "# 7. Definir codificação posicional\n",
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model, max_len=5000):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-np.log(10000.0) / d_model))\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        pe = pe.unsqueeze(0)\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x + self.pe[:, :x.size(1), :]\n",
    "        return x\n",
    "\n",
    "# 8. Definir o modelo Transformer com dropout adicional\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, input_dim, d_model, nhead, num_layers, dim_feedforward, dropout=0.1):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.pos_encoder = PositionalEncoding(d_model)\n",
    "        self.encoder_layer = nn.TransformerEncoderLayer(\n",
    "            d_model=d_model, nhead=nhead, dim_feedforward=dim_feedforward, dropout=dropout, batch_first=True\n",
    "        )\n",
    "        self.transformer_encoder = nn.TransformerEncoder(self.encoder_layer, num_layers=num_layers)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.linear_out = nn.Linear(d_model, 1, bias=True)\n",
    "\n",
    "    def forward(self, src):\n",
    "        src = self.pos_encoder(src)\n",
    "        output = self.transformer_encoder(src)\n",
    "        output = self.dropout(output[:, -1, :])\n",
    "        output = self.linear_out(output)\n",
    "        return output\n",
    "\n",
    "# Outros hiperparâmetros fixos\n",
    "input_dim = d_model\n",
    "batch_size = 32\n",
    "num_epochs = 50\n",
    "\n",
    "# Função para calcular SMAPE\n",
    "def smape(y_true, y_pred):\n",
    "    denominator = (np.abs(y_true) + np.abs(y_pred)) / 2\n",
    "    diff = np.abs(y_true - y_pred) / denominator\n",
    "    return 100 * np.mean(diff)\n",
    "\n",
    "# Função de treinamento e avaliação para uma repetição\n",
    "def train_and_evaluate(learning_rate, num_layers, nhead, dim_feedforward, dropout_rate, weight_decay):\n",
    "    model = Encoder(input_dim, d_model, nhead, num_layers, dim_feedforward, dropout=dropout_rate)\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', patience=5, factor=0.5)\n",
    "\n",
    "    best_val_loss = float('inf')\n",
    "    patience = 10\n",
    "    patience_counter = 0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        for i in range(0, len(X_train), batch_size):\n",
    "            X_batch = X_train[i:i + batch_size]\n",
    "            y_batch = y_train[i:i + batch_size]\n",
    "            outputs = model(X_batch)\n",
    "            loss = criterion(outputs, y_batch)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            y_val_pred = model(X_val)\n",
    "            val_loss = criterion(y_val_pred, y_val)\n",
    "        \n",
    "        scheduler.step(val_loss)\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            patience_counter = 0\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "            if patience_counter >= patience:\n",
    "                break\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        y_pred = model(X_test)\n",
    "    \n",
    "    y_pred_rescaled = scaler.inverse_transform(y_pred.numpy()) / MB\n",
    "    y_test_rescaled = scaler.inverse_transform(y_test.numpy()) / MB\n",
    "    \n",
    "    mae = mean_absolute_error(y_test_rescaled, y_pred_rescaled)\n",
    "    rmse = np.sqrt(mean_squared_error(y_test_rescaled, y_pred_rescaled))\n",
    "    mape = mean_absolute_percentage_error(y_test_rescaled, y_pred_rescaled) * 100\n",
    "    smape_val = smape(y_test_rescaled, y_pred_rescaled)\n",
    "    \n",
    "    return mae, rmse, mape, smape_val, model\n",
    "\n",
    "# Função de mapeamento de valores contínuos para discretos\n",
    "def map_continuous_to_discrete(value, discrete_values):\n",
    "    idx = int(round(value * (len(discrete_values) - 1)))\n",
    "    idx = max(0, min(idx, len(discrete_values) - 1))\n",
    "    return discrete_values[idx]\n",
    "\n",
    "# Implementação do MRFO\n",
    "class MRFO:\n",
    "    def __init__(self, objective_func, bounds, n_mantas=30, max_iter=100):\n",
    "        self.objective_func = objective_func\n",
    "        self.bounds = np.array(bounds).T  # Shape: (2, dim)\n",
    "        self.n_mantas = n_mantas\n",
    "        self.max_iter = max_iter\n",
    "        self.dim = self.bounds.shape[1]\n",
    "        \n",
    "        # Inicializar população\n",
    "        self.positions = np.zeros((self.n_mantas, self.dim))\n",
    "        for d in range(self.dim):\n",
    "            self.positions[:, d] = np.random.uniform(self.bounds[0, d], self.bounds[1, d], self.n_mantas)\n",
    "        self.fitness = np.array([float('inf')] * self.n_mantas)\n",
    "        self.best_position = None\n",
    "        self.best_fitness = float('inf')\n",
    "\n",
    "    def optimize(self):\n",
    "        for t in range(self.max_iter):\n",
    "            # Avaliar fitness de todas as mantas\n",
    "            for i in range(self.n_mantas):\n",
    "                self.fitness[i] = self.objective_func(self.positions[i])\n",
    "                if self.fitness[i] < self.best_fitness:\n",
    "                    self.best_fitness = self.fitness[i]\n",
    "                    self.best_position = self.positions[i].copy()\n",
    "\n",
    "            # Atualizar posições usando Chain Foraging, Cyclone Foraging e Somersault Foraging\n",
    "            for i in range(self.n_mantas):\n",
    "                r = np.random.random(self.dim)\n",
    "                r1 = np.random.random()\n",
    "\n",
    "                # Chain Foraging\n",
    "                if r1 < 0.5:\n",
    "                    if i == 0:\n",
    "                        self.positions[i] = self.positions[i] + r * (self.best_position - self.positions[i]) + \\\n",
    "                                            r * (self.best_position - self.positions[i])\n",
    "                    else:\n",
    "                        self.positions[i] = self.positions[i] + r * (self.positions[i-1] - self.positions[i]) + \\\n",
    "                                            r * (self.best_position - self.positions[i])\n",
    "\n",
    "                # Cyclone Foraging\n",
    "                else:\n",
    "                    beta = 2 * np.exp(r1 * (self.max_iter - t + 1) / self.max_iter) * np.sin(2 * np.pi * r1)\n",
    "                    if r1 < 0.5:\n",
    "                        self.positions[i] = self.positions[i] + r * (self.best_position - beta * self.positions[i])\n",
    "                    else:\n",
    "                        idx = np.random.randint(0, self.n_mantas)\n",
    "                        self.positions[i] = self.positions[i] + r * (self.positions[idx] - beta * self.positions[i])\n",
    "\n",
    "                # Somersault Foraging\n",
    "                r2 = np.random.random()\n",
    "                self.positions[i] = self.positions[i] + 0.5 * (self.best_position + self.positions[i]) * (2 * r2 - 1)\n",
    "\n",
    "                # Garantir que as posições estejam dentro dos limites\n",
    "                self.positions[i] = np.clip(self.positions[i], self.bounds[0], self.bounds[1])\n",
    "\n",
    "        return self.best_position, self.best_fitness\n",
    "\n",
    "# Função objetivo para o MRFO (minimizar MAE médio)\n",
    "def objective_function(params):\n",
    "    # Desempacotar parâmetros\n",
    "    lr = 10 ** params[0]  # learning_rate (log scale)\n",
    "    nl = map_continuous_to_discrete(params[1], [2, 3])  # num_layers\n",
    "    nh = map_continuous_to_discrete(params[2], [4, 8])  # nhead\n",
    "    df = map_continuous_to_discrete(params[3], [256, 512])  # dim_feedforward\n",
    "    dr = params[4]  # dropout_rate\n",
    "    wd = params[5]  # weight_decay\n",
    "\n",
    "    # Executar repetições em paralelo\n",
    "    results = Parallel(n_jobs=-1)(\n",
    "        delayed(train_and_evaluate)(lr, nl, nh, df, dr, wd) for _ in range(n_repetitions)\n",
    "    )\n",
    "\n",
    "    mae_list = [result[0] for result in results]\n",
    "    return np.mean(mae_list)\n",
    "\n",
    "# MRFO para otimizar hiperparâmetros\n",
    "n_repetitions = 5\n",
    "bounds = [\n",
    "    [-3.3, -2.7],  # log10(learning_rate): [0.0005, 0.002]\n",
    "    [0, 1],        # num_layers (mapeado para [2, 3])\n",
    "    [0, 1],        # nhead (mapeado para [4, 8])\n",
    "    [0, 1],        # dim_feedforward (mapeado para [256, 512])\n",
    "    [0.1, 0.3],    # dropout_rate\n",
    "    [0.0, 0.1]     # weight_decay\n",
    "]\n",
    "\n",
    "mrfo = MRFO(objective_function, bounds, n_mantas=30, max_iter=20)\n",
    "best_position, best_fitness = mrfo.optimize()\n",
    "\n",
    "# Mapear a melhor posição para hiperparâmetros\n",
    "best_lr = 10 ** best_position[0]\n",
    "best_nl = map_continuous_to_discrete(best_position[1], [2, 3])\n",
    "best_nh = map_continuous_to_discrete(best_position[2], [4, 8])\n",
    "best_df = map_continuous_to_discrete(best_position[3], [256, 512])\n",
    "best_dr = best_position[4]\n",
    "best_wd = best_position[5]\n",
    "\n",
    "# Treinar o modelo com a melhor configuração para obter métricas finais\n",
    "with mlflow.start_run(run_name=\"Best_MRFO_Run\"):\n",
    "    # Registrar hiperparâmetros\n",
    "    mlflow.log_param(\"learning_rate\", best_lr)\n",
    "    mlflow.log_param(\"num_layers\", best_nl)\n",
    "    mlflow.log_param(\"nhead\", best_nh)\n",
    "    mlflow.log_param(\"dim_feedforward\", best_df)\n",
    "    mlflow.log_param(\"dropout_rate\", best_dr)\n",
    "    mlflow.log_param(\"weight_decay\", best_wd)\n",
    "    mlflow.log_param(\"seq_length\", SEQ_LENGTH)\n",
    "    mlflow.log_param(\"resample_interval\", \"15min\")\n",
    "    mlflow.log_param(\"batch_size\", batch_size)\n",
    "    mlflow.log_param(\"num_epochs\", num_epochs)\n",
    "\n",
    "    print(f\"\\nBest MRFO Configuration: LR={best_lr}, Layers={best_nl}, Heads={best_nh}, FF={best_df}, Dropout={best_dr}, Weight Decay={best_wd}\")\n",
    "    \n",
    "    results = Parallel(n_jobs=-1)(\n",
    "        delayed(train_and_evaluate)(best_lr, best_nl, best_nh, best_df, best_dr, best_wd) for _ in range(n_repetitions)\n",
    "    )\n",
    "\n",
    "    mae_list = [result[0] for result in results]\n",
    "    rmse_list = [result[1] for result in results]\n",
    "    mape_list = [result[2] for result in results]\n",
    "    smape_list = [result[3] for result in results]\n",
    "    models = [result[4] for result in results]\n",
    "\n",
    "    for rep, (mae, rmse, mape, smape_val, _) in enumerate(results):\n",
    "        print(f\"  Repetition {rep+1}/{n_repetitions}\")\n",
    "        print(f\"    MAE: {mae}, RMSE: {rmse}, MAPE: {mape}%, SMAPE: {smape_val}%\")\n",
    "\n",
    "    avg_mae = np.mean(mae_list)\n",
    "    avg_rmse = np.mean(rmse_list)\n",
    "    avg_mape = np.mean(mape_list)\n",
    "    avg_smape = np.mean(smape_list)\n",
    "    std_mae = np.std(mae_list)\n",
    "    std_rmse = np.std(rmse_list)\n",
    "    std_mape = np.std(mape_list)\n",
    "    std_smape = np.std(smape_list)\n",
    "\n",
    "    print(f\"  Average MAE: {avg_mae} (±{std_mae}), Average RMSE: {avg_rmse} (±{std_rmse})\")\n",
    "    print(f\"  Average MAPE: {avg_mape}% (±{std_mape}), Average SMAPE: {avg_smape}% (±{std_smape})\")\n",
    "\n",
    "    # Registrar métricas no MLflow\n",
    "    mlflow.log_metric(\"avg_mae\", avg_mae)\n",
    "    mlflow.log_metric(\"std_mae\", std_mae)\n",
    "    mlflow.log_metric(\"avg_rmse\", avg_rmse)\n",
    "    mlflow.log_metric(\"std_rmse\", std_rmse)\n",
    "    mlflow.log_metric(\"avg_mape\", avg_mape)\n",
    "    mlflow.log_metric(\"std_mape\", std_mape)\n",
    "    mlflow.log_metric(\"avg_smape\", avg_smape)\n",
    "    mlflow.log_metric(\"std_smape\", std_smape)\n",
    "\n",
    "    best_model = models[0]\n",
    "    mlflow.pytorch.log_model(best_model, \"best_model\")\n",
    "\n",
    "# 9. Fazer previsões\n",
    "model = best_model\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    y_train_pred = model(X_train)\n",
    "    y_test_pred = model(X_test)\n",
    "\n",
    "# 10. Reverter o escalonamento e converter para MB\n",
    "y_train_pred_mb = scaler.inverse_transform(y_train_pred.numpy()) / MB\n",
    "y_train_mb = scaler.inverse_transform(y_train.numpy()) / MB\n",
    "y_test_pred_mb = scaler.inverse_transform(y_test_pred.numpy()) / MB\n",
    "y_test_mb = scaler.inverse_transform(y_test.numpy()) / MB\n",
    "\n",
    "# 11. Preparar dados para plotagem\n",
    "train_df = pd.DataFrame({\n",
    "    'date': y_dates_train,\n",
    "    'actual': y_train_mb.flatten(),\n",
    "    'predicted': y_train_pred_mb.flatten()\n",
    "}).sort_values('date')\n",
    "\n",
    "test_df = pd.DataFrame({\n",
    "    'date': y_dates_test,\n",
    "    'actual': y_test_mb.flatten(),\n",
    "    'predicted': y_test_pred_mb.flatten()\n",
    "}).sort_values('date')\n",
    "\n",
    "# 12. Plotar os resultados\n",
    "plt.style.use('default')\n",
    "fig, axs = plt.subplots(2, 1, figsize=(15, 10), sharex=False)\n",
    "\n",
    "axs[0].plot(train_df['date'], train_df['actual'], label='Real', color='blue', linewidth=1.5)\n",
    "axs[0].plot(train_df['date'], train_df['predicted'], label='Predito', color='red', alpha=0.7, linewidth=1.5)\n",
    "axs[0].set_title('Conjunto de Treinamento (60%)', fontsize=12, pad=10)\n",
    "axs[0].set_ylabel('Consumo de Memória (MB)', fontsize=10)\n",
    "axs[0].legend(loc='upper left', fontsize=10)\n",
    "axs[0].grid(True, linestyle='--', alpha=0.7)\n",
    "\n",
    "axs[1].plot(test_df['date'], test_df['actual'], label='Real', color='blue', linewidth=1.5)\n",
    "axs[1].plot(test_df['date'], test_df['predicted'], label='Predito', color='red', alpha=0.7, linewidth=1.5)\n",
    "axs[1].set_title('Conjunto de Teste (20%)', fontsize=12, pad=10)\n",
    "axs[1].set_xlabel('Data', fontsize=10)\n",
    "axs[1].set_ylabel('Consumo de Memória (MB)', fontsize=10)\n",
    "axs[1].legend(loc='upper left', fontsize=10)\n",
    "axs[1].grid(True, linestyle='--', alpha=0.7)\n",
    "\n",
    "for ax in axs:\n",
    "    ax.xaxis.set_major_locator(mdates.AutoDateLocator())\n",
    "    ax.xaxis.set_major_formatter(mdates.DateFormatter('%Y-%m-%d'))\n",
    "    ax.tick_params(axis='x', rotation=45, labelsize=9)\n",
    "    ax.tick_params(axis='y', labelsize=9)\n",
    "\n",
    "plt.suptitle('Predições do Transformer Otimizado - Prometheus (MB, Resample 15min)', fontsize=14, y=0.98)\n",
    "plt.tight_layout(rect=[0, 0, 1, 0.95])\n",
    "plt.savefig(os.path.join(DATA_DIR, 'prometheus_transformer_mrfo_15min-mrfo.png'), dpi=300, bbox_inches='tight')\n",
    "plt.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
