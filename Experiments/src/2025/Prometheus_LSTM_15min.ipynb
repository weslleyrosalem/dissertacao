{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import mlflow\n",
    "import mlflow.keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, LSTM, Dropout\n",
    "from keras.optimizers import Adam\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, mean_absolute_percentage_error\n",
    "import matplotlib.dates as mdates\n",
    "import tensorflow as tf\n",
    "\n",
    "# Configurar MLflow\n",
    "mlflow.set_tracking_uri(\"http://localhost:5001\")\n",
    "mlflow.set_experiment(\"Prometheus_LSTM_Experiment_MRFO_15min\")\n",
    "\n",
    "# Definindo constantes\n",
    "DATA_DIR = \"../../data/\"\n",
    "FILE_PATH = os.path.join(DATA_DIR, 'ts.pkl')\n",
    "SEQ_LENGTH = 48  # 12 horas (48 * 15min)\n",
    "MB = 1_048_576\n",
    "\n",
    "# 1. Carregar e reamostrar os dados para 15 minutos\n",
    "df = pd.read_pickle(FILE_PATH)\n",
    "ts = df['value'].astype(float)\n",
    "# Aplicar suavização com média móvel (window=3)\n",
    "ts = ts.rolling(window=3, min_periods=1).mean()\n",
    "ts = ts.resample('15min').mean().dropna()\n",
    "dates = ts.index\n",
    "\n",
    "# 2. Dividir os dados: 60% treino, 20% validação, 20% teste\n",
    "train_size = int(0.6 * len(ts))\n",
    "val_size = int(0.2 * len(ts))\n",
    "train = ts[:train_size]\n",
    "val = ts[train_size:train_size + val_size]\n",
    "test = ts[train_size + val_size:]\n",
    "\n",
    "# 3. Escalonar os dados\n",
    "scaler = StandardScaler()\n",
    "train_scaled = scaler.fit_transform(train.values.reshape(-1, 1))\n",
    "val_scaled = scaler.transform(val.values.reshape(-1, 1))\n",
    "test_scaled = scaler.transform(test.values.reshape(-1, 1))\n",
    "\n",
    "# 4. Criar sequências\n",
    "def create_sequences(data, dates, seq_length):\n",
    "    X, y, y_dates = [], [], []\n",
    "    for i in range(len(data) - seq_length):\n",
    "        X.append(data[i:i + seq_length])\n",
    "        y.append(data[i + seq_length])\n",
    "        y_dates.append(dates[i + seq_length])\n",
    "    return np.array(X), np.array(y), np.array(y_dates)\n",
    "\n",
    "X_train, y_train, y_dates_train = create_sequences(train_scaled, dates[:train_size], SEQ_LENGTH)\n",
    "X_val, y_val, y_dates_val = create_sequences(val_scaled, dates[train_size:train_size + val_size], SEQ_LENGTH)\n",
    "X_test, y_test, y_dates_test = create_sequences(test_scaled, dates[train_size + val_size:], SEQ_LENGTH)\n",
    "\n",
    "# 5. Reshape para 3D\n",
    "X_train = np.reshape(X_train, (X_train.shape[0], X_train.shape[1], 1))\n",
    "X_val = np.reshape(X_val, (X_val.shape[0], X_val.shape[1], 1))\n",
    "X_test = np.reshape(X_test, (X_test.shape[0], X_test.shape[1], 1))\n",
    "\n",
    "# 6. Função para calcular SMAPE\n",
    "def smape(y_true, y_pred):\n",
    "    denominator = (np.abs(y_true) + np.abs(y_pred)) / 2\n",
    "    diff = np.abs(y_true - y_pred) / denominator\n",
    "    return 100 * np.mean(diff)\n",
    "\n",
    "# 7. Função Objetivo para MRFO\n",
    "def objective_function(params):\n",
    "    lstm_units = max(50, min(150, int(params[0])))\n",
    "    dropout_rate = max(0.2, min(0.5, params[1]))\n",
    "    batch_size = max(32, min(128, int(params[2])))\n",
    "    learning_rate = max(0.0001, min(0.001, params[3]))\n",
    "    n_steps = max(10, min(min(len(train_scaled), len(test_scaled)) - 1, int(params[4])))\n",
    "    epochs = max(10, min(200, int(params[5])))\n",
    "\n",
    "    # Criar sequências com n_steps\n",
    "    X_train, y_train, _ = create_sequences(train_scaled, dates[:train_size], n_steps)\n",
    "    X_test, y_test, y_dates_test = create_sequences(test_scaled, dates[train_size + val_size:], n_steps)\n",
    "\n",
    "    if X_test.shape[0] == 0:\n",
    "        return float(\"inf\"), float(\"inf\"), float(\"inf\"), float(\"inf\")\n",
    "\n",
    "    X_train = np.reshape(X_train, (X_train.shape[0], X_train.shape[1], 1))\n",
    "    X_test = np.reshape(X_test, (X_test.shape[0], X_test.shape[1], 1))\n",
    "\n",
    "    # Definir o modelo\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(lstm_units, activation='tanh', input_shape=(n_steps, 1), return_sequences=True))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(LSTM(lstm_units, activation='tanh'))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(Dense(1))\n",
    "\n",
    "    optimizer = Adam(learning_rate=learning_rate)\n",
    "    model.compile(optimizer=optimizer, loss='mse')\n",
    "\n",
    "    # Treinar o modelo\n",
    "    model.fit(X_train, y_train, epochs=epochs, batch_size=batch_size, verbose=0)\n",
    "\n",
    "    # Fazer previsões\n",
    "    test_pred = model.predict(X_test, verbose=0)\n",
    "    test_pred = scaler.inverse_transform(test_pred) / MB\n",
    "    y_test_rescaled = scaler.inverse_transform(y_test) / MB\n",
    "\n",
    "    # Calcular métricas\n",
    "    rmse = np.sqrt(mean_squared_error(y_test_rescaled, test_pred))\n",
    "    mse = mean_squared_error(y_test_rescaled, test_pred)\n",
    "    mae = mean_absolute_error(y_test_rescaled, test_pred)\n",
    "    mape = mean_absolute_percentage_error(y_test_rescaled, test_pred) * 100\n",
    "    smape_val = smape(y_test_rescaled, test_pred)\n",
    "\n",
    "    # Registrar no MLflow\n",
    "    with mlflow.start_run():\n",
    "        mlflow.set_tag(\"modelo\", \"LSTM\")\n",
    "        mlflow.set_tag(\"otimização\", \"MRFO\")\n",
    "        mlflow.set_tag(\"versão\", \"v1.0\")\n",
    "        mlflow.log_param(\"lstm_units\", lstm_units)\n",
    "        mlflow.log_param(\"dropout_rate\", dropout_rate)\n",
    "        mlflow.log_param(\"batch_size\", batch_size)\n",
    "        mlflow.log_param(\"learning_rate\", learning_rate)\n",
    "        mlflow.log_param(\"n_steps\", n_steps)\n",
    "        mlflow.log_param(\"epochs\", epochs)\n",
    "        mlflow.log_param(\"resample_interval\", \"15min\")\n",
    "        mlflow.log_param(\"seq_length\", n_steps)\n",
    "        mlflow.log_metric(\"rmse\", rmse)\n",
    "        mlflow.log_metric(\"mse\", mse)\n",
    "        mlflow.log_metric(\"mae\", mae)\n",
    "        mlflow.log_metric(\"mape\", mape)\n",
    "        mlflow.log_metric(\"smape\", smape_val)\n",
    "        mlflow.keras.log_model(model, \"model\")\n",
    "\n",
    "    return rmse, mse, mae, mape, smape_val\n",
    "\n",
    "# 8. Implementação do MRFO\n",
    "class MRFO:\n",
    "    def __init__(self, obj_func, dim, SearchAgents_no, max_iter, lb, ub):\n",
    "        self.obj_func = obj_func\n",
    "        self.dim = dim\n",
    "        self.SearchAgents_no = SearchAgents_no\n",
    "        self.max_iter = max_iter\n",
    "        self.lb = lb\n",
    "        self.ub = ub\n",
    "        self.positions = np.random.uniform(0, 1, (self.SearchAgents_no, self.dim)) * (self.ub - self.lb) + self.lb\n",
    "        self.fitness = np.array([self.obj_func(self.clip_params(ind))[0] for ind in self.positions])\n",
    "        self.best_idx = np.argmin(self.fitness)\n",
    "        self.gbest = self.positions[self.best_idx].copy()\n",
    "        self.gbest_fitness = self.fitness[self.best_idx]\n",
    "\n",
    "    def clip_params(self, params):\n",
    "        params[0] = max(50, min(150, params[0]))  # lstm_units\n",
    "        params[1] = max(0.2, min(0.5, params[1]))  # dropout_rate\n",
    "        params[2] = max(32, min(128, params[2]))  # batch_size\n",
    "        params[3] = max(0.0001, min(0.001, params[3]))  # learning_rate\n",
    "        params[4] = max(10, min(min(len(train_scaled), len(test_scaled)) - 1, params[4]))  # n_steps\n",
    "        params[5] = max(10, min(200, params[5]))  # epochs\n",
    "        return params\n",
    "\n",
    "    def chain_foraging(self, i):\n",
    "        r = np.random.rand(self.dim)\n",
    "        self.positions[i] = self.positions[i] + r * (self.gbest - self.positions[i])\n",
    "        self.positions[i] = self.clip_params(self.positions[i])\n",
    "\n",
    "    def cyclone_foraging(self, i, t, max_iter):\n",
    "        r = np.random.rand(self.dim)\n",
    "        A = 2 * (1 - t / max_iter)\n",
    "        direction = np.random.choice([-1, 1], size=self.dim)\n",
    "        self.positions[i] = self.positions[i] + A * direction * r * (self.gbest - self.positions[i])\n",
    "        self.positions[i] = self.clip_params(self.positions[i])\n",
    "\n",
    "    def somersault_foraging(self, i):\n",
    "        S = 2 * np.random.rand(self.dim) - 1\n",
    "        somersault_factor = 2\n",
    "        self.positions[i] = self.positions[i] + somersault_factor * (S * self.gbest - self.positions[i])\n",
    "        self.positions[i] = self.clip_params(self.positions[i])\n",
    "\n",
    "    def optimize(self):\n",
    "        for t in range(self.max_iter):\n",
    "            for i in range(self.SearchAgents_no):\n",
    "                if np.random.rand() < 0.5:\n",
    "                    self.chain_foraging(i)\n",
    "                else:\n",
    "                    self.cyclone_foraging(i, t, self.max_iter)\n",
    "\n",
    "                fitness_candidate = self.obj_func(self.clip_params(self.positions[i]))[0]\n",
    "\n",
    "                if fitness_candidate < self.fitness[i]:\n",
    "                    self.fitness[i] = fitness_candidate\n",
    "                    if fitness_candidate < self.gbest_fitness:\n",
    "                        self.gbest_fitness = fitness_candidate\n",
    "                        self.gbest = self.positions[i].copy()\n",
    "\n",
    "            for i in range(self.SearchAgents_no):\n",
    "                self.somersault_foraging(i)\n",
    "\n",
    "            print(f\"Iteração {t+1}/{self.max_iter}, Melhor Fitness (RMSE): {self.gbest_fitness:.4f}\")\n",
    "\n",
    "        return self.gbest, self.gbest_fitness\n",
    "\n",
    "# 9. Configurar e executar MRFO\n",
    "dim = 6\n",
    "SearchAgents_no = 10\n",
    "max_iter = 20\n",
    "lb = np.array([50, 0.2, 32, 0.0001, 10, 10])\n",
    "ub = np.array([150, 0.5, 128, 0.001, 100, 200])\n",
    "mrfo = MRFO(objective_function, dim, SearchAgents_no, max_iter, lb, ub)\n",
    "best_params, best_fitness = mrfo.optimize()\n",
    "\n",
    "# 10. Treinar com melhores hiperparâmetros e calcular métricas\n",
    "def train_and_evaluate(params):\n",
    "    lstm_units = max(50, min(150, int(params[0])))\n",
    "    dropout_rate = max(0.2, min(0.5, params[1]))\n",
    "    batch_size = max(32, min(128, int(params[2])))\n",
    "    learning_rate = max(0.0001, min(0.001, params[3]))\n",
    "    n_steps = max(10, min(min(len(train_scaled), len(test_scaled)) - 1, int(params[4])))\n",
    "    epochs = max(10, min(200, int(params[5])))\n",
    "\n",
    "    X_train, y_train, _ = create_sequences(train_scaled, dates[:train_size], n_steps)\n",
    "    X_test, y_test, y_dates_test = create_sequences(test_scaled, dates[train_size + val_size:], n_steps)\n",
    "\n",
    "    if X_test.shape[0] == 0:\n",
    "        return float(\"inf\"), float(\"inf\"), float(\"inf\"), float(\"inf\"), None\n",
    "\n",
    "    X_train = np.reshape(X_train, (X_train.shape[0], X_train.shape[1], 1))\n",
    "    X_test = np.reshape(X_test, (X_test.shape[0], X_test.shape[1], 1))\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(lstm_units, activation='tanh', input_shape=(n_steps, 1), return_sequences=True))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(LSTM(lstm_units, activation='tanh'))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(Dense(1))\n",
    "\n",
    "    optimizer = Adam(learning_rate=learning_rate)\n",
    "    model.compile(optimizer=optimizer, loss='mse')\n",
    "\n",
    "    model.fit(X_train, y_train, epochs=epochs, batch_size=batch_size, verbose=0)\n",
    "\n",
    "    test_pred = model.predict(X_test, verbose=0)\n",
    "    test_pred = scaler.inverse_transform(test_pred) / MB\n",
    "    y_test_rescaled = scaler.inverse_transform(y_test) / MB\n",
    "\n",
    "    rmse = np.sqrt(mean_squared_error(y_test_rescaled, test_pred))\n",
    "    mse = mean_squared_error(y_test_rescaled, test_pred)\n",
    "    mae = mean_absolute_error(y_test_rescaled, test_pred)\n",
    "    mape = mean_absolute_percentage_error(y_test_rescaled, test_pred) * 100\n",
    "    smape_val = smape(y_test_rescaled, test_pred)\n",
    "\n",
    "    return rmse, mse, mae, mape, smape_val, model, y_test_rescaled, test_pred, y_dates_test\n",
    "\n",
    "# 11. Executar repetições com melhores hiperparâmetros\n",
    "n_repetitions = 5\n",
    "with mlflow.start_run(run_name=\"Best_MRFO_Run\"):\n",
    "    mlflow.log_param(\"lstm_units\", int(best_params[0]))\n",
    "    mlflow.log_param(\"dropout_rate\", best_params[1])\n",
    "    mlflow.log_param(\"batch_size\", int(best_params[2]))\n",
    "    mlflow.log_param(\"learning_rate\", best_params[3])\n",
    "    mlflow.log_param(\"n_steps\", int(best_params[4]))\n",
    "    mlflow.log_param(\"epochs\", int(best_params[5]))\n",
    "    mlflow.log_param(\"resample_interval\", \"15min\")\n",
    "    mlflow.log_param(\"seq_length\", SEQ_LENGTH)\n",
    "\n",
    "    print(f\"\\nBest MRFO Configuration: LSTM Units={int(best_params[0])}, Dropout Rate={best_params[1]:.2f}, \"\n",
    "          f\"Batch Size={int(best_params[2])}, Learning Rate={best_params[3]:.6f}, \"\n",
    "          f\"n_steps={int(best_params[4])}, Epochs={int(best_params[5])}\")\n",
    "\n",
    "    results = [train_and_evaluate(best_params) for _ in range(n_repetitions)]\n",
    "\n",
    "    rmse_list = [result[0] for result in results]\n",
    "    mse_list = [result[1] for result in results]\n",
    "    mae_list = [result[2] for result in results]\n",
    "    mape_list = [result[3] for result in results]\n",
    "    smape_list = [result[4] for result in results]\n",
    "    models = [result[5] for result in results]\n",
    "    y_test_rescaled = results[0][6]\n",
    "    test_pred = results[0][7]\n",
    "    y_dates_test = results[0][8]\n",
    "\n",
    "    for rep, (rmse, mse, mae, mape, smape_val, _, _, _, _) in enumerate(results):\n",
    "        print(f\"  Repetition {rep+1}/{n_repetitions}\")\n",
    "        print(f\"    MAE: {mae}, RMSE: {rmse}, MAPE: {mape}%, SMAPE: {smape_val}%\")\n",
    "\n",
    "    avg_rmse = np.mean(rmse_list)\n",
    "    avg_mse = np.mean(mse_list)\n",
    "    avg_mae = np.mean(mae_list)\n",
    "    avg_mape = np.mean(mape_list)\n",
    "    avg_smape = np.mean(smape_list)\n",
    "    std_rmse = np.std(rmse_list)\n",
    "    std_mse = np.std(mse_list)\n",
    "    std_mae = np.std(mae_list)\n",
    "    std_mape = np.std(mape_list)\n",
    "    std_smape = np.std(smape_list)\n",
    "\n",
    "    print(f\"  Average RMSE: {avg_rmse} (±{std_rmse}), Average MSE: {avg_mse} (±{std_mse})\")\n",
    "    print(f\"  Average MAE: {avg_mae} (±{std_mae}), Average MAPE: {avg_mape}% (±{std_mape})\")\n",
    "    print(f\"  Average SMAPE: {avg_smape}% (±{std_smape})\")\n",
    "\n",
    "    mlflow.log_metric(\"avg_rmse\", avg_rmse)\n",
    "    mlflow.log_metric(\"std_rmse\", std_rmse)\n",
    "    mlflow.log_metric(\"avg_mse\", avg_mse)\n",
    "    mlflow.log_metric(\"std_mse\", std_mse)\n",
    "    mlflow.log_metric(\"avg_mae\", avg_mae)\n",
    "    mlflow.log_metric(\"std_mae\", std_mae)\n",
    "    mlflow.log_metric(\"avg_mape\", avg_mape)\n",
    "    mlflow.log_metric(\"std_mape\", std_mape)\n",
    "    mlflow.log_metric(\"avg_smape\", avg_smape)\n",
    "    mlflow.log_metric(\"std_smape\", std_smape)\n",
    "\n",
    "    best_model = models[0]\n",
    "    mlflow.keras.log_model(best_model, \"best_model\")\n",
    "\n",
    "# 12. Plotar resultados\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(y_dates_test, scaler.inverse_transform(y_test_rescaled * MB), label=\"Valores Reais\", color='blue')\n",
    "plt.plot(y_dates_test, scaler.inverse_transform(test_pred * MB), label=\"Previsões do Modelo\", color='red', linestyle='--')\n",
    "plt.title(\"Valores Reais vs Previsões do Modelo - Consumo de Memória\")\n",
    "plt.xlabel(\"Data\")\n",
    "plt.ylabel(\"Consumo de Memória (Bytes)\")\n",
    "plt.legend()\n",
    "plt.gca().xaxis.set_major_locator(mdates.AutoDateLocator())\n",
    "plt.gca().xaxis.set_major_formatter(mdates.DateFormatter('%Y-%m-%d'))\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(DATA_DIR, 'prometheus_lstm_mrfo_15min.png'), dpi=300, bbox_inches='tight')\n",
    "plt.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}