{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a4972e03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Testing combination: LR=0.0001, Layers=2, Heads=4, FF=256\n",
      "  Repetition 1/5\n",
      "    MAE: 18.479503631591797, RMSE: 26.878705004423924\n",
      "  Repetition 2/5\n",
      "    MAE: 20.714757919311523, RMSE: 26.27941525254367\n",
      "  Repetition 3/5\n",
      "    MAE: 12.292089462280273, RMSE: 15.233248155440597\n",
      "  Repetition 4/5\n",
      "    MAE: 16.082731246948242, RMSE: 19.350572113332497\n",
      "  Repetition 5/5\n",
      "    MAE: 22.83884620666504, RMSE: 31.594968023318703\n",
      "  Average MAE: 18.081585693359376 (±3.667073709544625), Average RMSE: 23.867381709811877 (±5.823253303681761)\n",
      "\n",
      "Testing combination: LR=0.0001, Layers=2, Heads=4, FF=512\n",
      "  Repetition 1/5\n",
      "    MAE: 17.34595489501953, RMSE: 23.81189380585034\n",
      "  Repetition 2/5\n",
      "    MAE: 13.186022758483887, RMSE: 17.113495686712888\n",
      "  Repetition 3/5\n",
      "    MAE: 17.213817596435547, RMSE: 21.703783062377628\n",
      "  Repetition 4/5\n",
      "    MAE: 16.213184356689453, RMSE: 24.491914621685613\n",
      "  Repetition 5/5\n",
      "    MAE: 18.022062301635742, RMSE: 22.660091269192296\n",
      "  Average MAE: 16.396208381652833 (±1.7060301149621007), Average RMSE: 21.95623568916375 (±2.6032445306772987)\n",
      "\n",
      "Testing combination: LR=0.0001, Layers=2, Heads=8, FF=256\n",
      "  Repetition 1/5\n",
      "    MAE: 13.627840042114258, RMSE: 16.77897029004285\n",
      "  Repetition 2/5\n",
      "    MAE: 24.797330856323242, RMSE: 32.26961045301078\n",
      "  Repetition 3/5\n",
      "    MAE: 25.47861671447754, RMSE: 31.41090897501565\n",
      "  Repetition 4/5\n",
      "    MAE: 24.45696258544922, RMSE: 36.58152716717568\n",
      "  Repetition 5/5\n",
      "    MAE: 24.531339645385742, RMSE: 29.99896543626286\n",
      "  Average MAE: 22.57841796875 (±4.4897751689843135), Average RMSE: 29.40799646430156 (±6.685829527096268)\n",
      "\n",
      "Testing combination: LR=0.0001, Layers=2, Heads=8, FF=512\n",
      "  Repetition 1/5\n",
      "    MAE: 13.139766693115234, RMSE: 16.751977604513126\n",
      "  Repetition 2/5\n",
      "    MAE: 13.262666702270508, RMSE: 16.760341810869715\n",
      "  Repetition 3/5\n",
      "    MAE: 16.503202438354492, RMSE: 20.01581177337721\n",
      "  Repetition 4/5\n",
      "    MAE: 19.137903213500977, RMSE: 24.9890723187469\n",
      "  Repetition 5/5\n",
      "    MAE: 18.17548370361328, RMSE: 23.436522115016473\n",
      "  Average MAE: 16.043804550170897 (±2.4696846995333566), Average RMSE: 20.390745124504683 (±3.375867377822283)\n",
      "\n",
      "Testing combination: LR=0.0001, Layers=3, Heads=4, FF=256\n",
      "  Repetition 1/5\n",
      "    MAE: 18.994909286499023, RMSE: 26.333068202490786\n",
      "  Repetition 2/5\n",
      "    MAE: 10.708476066589355, RMSE: 12.684643954827514\n",
      "  Repetition 3/5\n",
      "    MAE: 22.397733688354492, RMSE: 30.924979710861372\n",
      "  Repetition 4/5\n",
      "    MAE: 14.663753509521484, RMSE: 17.20958541982536\n",
      "  Repetition 5/5\n",
      "    MAE: 23.753156661987305, RMSE: 32.58957195477278\n",
      "  Average MAE: 18.103605842590333 (±4.8512247674799625), Average RMSE: 23.948369848555565 (±7.762898709071416)\n",
      "\n",
      "Testing combination: LR=0.0001, Layers=3, Heads=4, FF=512\n",
      "  Repetition 1/5\n",
      "    MAE: 21.257535934448242, RMSE: 29.245229478764994\n",
      "  Repetition 2/5\n",
      "    MAE: 18.612825393676758, RMSE: 25.827700815104144\n",
      "  Repetition 3/5\n",
      "    MAE: 11.725976943969727, RMSE: 13.182983203455056\n",
      "  Repetition 4/5\n",
      "    MAE: 20.316450119018555, RMSE: 27.113891014339863\n",
      "  Repetition 5/5\n",
      "    MAE: 4.64080810546875, RMSE: 6.5004237110246565\n",
      "  Average MAE: 15.310719299316407 (±6.293222647077099), Average RMSE: 20.37404564453774 (±8.922494466622538)\n",
      "\n",
      "Testing combination: LR=0.0001, Layers=3, Heads=8, FF=256\n",
      "  Repetition 1/5\n",
      "    MAE: 20.415760040283203, RMSE: 25.807151997814117\n",
      "  Repetition 2/5\n",
      "    MAE: 21.24092674255371, RMSE: 30.298827054828994\n",
      "  Repetition 3/5\n",
      "    MAE: 19.941036224365234, RMSE: 24.505605873723695\n",
      "  Repetition 4/5\n",
      "    MAE: 17.450923919677734, RMSE: 25.48723327586958\n",
      "  Repetition 5/5\n",
      "    MAE: 15.789925575256348, RMSE: 24.13380263629211\n",
      "  Average MAE: 18.967714500427245 (±2.0303044638836427), Average RMSE: 26.0465241677057 (±2.2129219609696187)\n",
      "\n",
      "Testing combination: LR=0.0001, Layers=3, Heads=8, FF=512\n",
      "  Repetition 1/5\n",
      "    MAE: 13.352840423583984, RMSE: 18.501868901060543\n",
      "  Repetition 2/5\n",
      "    MAE: 19.882001876831055, RMSE: 26.344183251923706\n",
      "  Repetition 3/5\n",
      "    MAE: 13.98065185546875, RMSE: 19.97077943521484\n",
      "  Repetition 4/5\n",
      "    MAE: 11.514449119567871, RMSE: 15.326451014765546\n",
      "  Repetition 5/5\n",
      "    MAE: 18.57843017578125, RMSE: 25.25462978710228\n",
      "  Average MAE: 15.461674690246582 (±3.2085715669210764), Average RMSE: 21.079582478013386 (±4.15017142893462)\n",
      "\n",
      "Testing combination: LR=0.0001, Layers=4, Heads=4, FF=256\n",
      "  Repetition 1/5\n",
      "    MAE: 19.100740432739258, RMSE: 24.70297304863134\n",
      "  Repetition 2/5\n",
      "    MAE: 14.057226181030273, RMSE: 18.608798565012282\n",
      "  Repetition 3/5\n",
      "    MAE: 32.98802947998047, RMSE: 45.205398750280644\n",
      "  Repetition 4/5\n",
      "    MAE: 26.51698875427246, RMSE: 36.45729555814669\n",
      "  Repetition 5/5\n",
      "    MAE: 25.612674713134766, RMSE: 36.95642328039454\n",
      "  Average MAE: 23.655131912231447 (±6.511335524841219), Average RMSE: 32.3861778404931 (±9.493591345323464)\n",
      "\n",
      "Testing combination: LR=0.0001, Layers=4, Heads=4, FF=512\n",
      "  Repetition 1/5\n",
      "    MAE: 19.73927879333496, RMSE: 25.832718511668975\n",
      "  Repetition 2/5\n",
      "    MAE: 11.580147743225098, RMSE: 19.313674841641916\n",
      "  Repetition 3/5\n",
      "    MAE: 11.207039833068848, RMSE: 19.728518622073082\n",
      "  Repetition 4/5\n",
      "    MAE: 12.687430381774902, RMSE: 25.3078156834597\n",
      "  Repetition 5/5\n",
      "    MAE: 15.224263191223145, RMSE: 26.642146217565223\n",
      "  Average MAE: 14.087631988525391 (±3.1552779606023296), Average RMSE: 23.36497477528178 (±3.169892336077229)\n",
      "\n",
      "Testing combination: LR=0.0001, Layers=4, Heads=8, FF=256\n",
      "  Repetition 1/5\n",
      "    MAE: 19.919294357299805, RMSE: 25.856031458693902\n",
      "  Repetition 2/5\n",
      "    MAE: 21.28173065185547, RMSE: 27.675323357627075\n",
      "  Repetition 3/5\n",
      "    MAE: 17.905590057373047, RMSE: 27.369795631144655\n",
      "  Repetition 4/5\n",
      "    MAE: 11.463736534118652, RMSE: 14.544968952396285\n",
      "  Repetition 5/5\n",
      "    MAE: 17.537328720092773, RMSE: 31.53238430194623\n",
      "  Average MAE: 17.62153606414795 (±3.3669864922069563), Average RMSE: 25.395700740361626 (±5.73938846489046)\n",
      "\n",
      "Testing combination: LR=0.0001, Layers=4, Heads=8, FF=512\n",
      "  Repetition 1/5\n",
      "    MAE: 13.448396682739258, RMSE: 20.111711178158657\n",
      "  Repetition 2/5\n",
      "    MAE: 11.869319915771484, RMSE: 20.894900401604424\n",
      "  Repetition 3/5\n",
      "    MAE: 12.691996574401855, RMSE: 17.021623211030175\n",
      "  Repetition 4/5\n",
      "    MAE: 18.0264892578125, RMSE: 24.9701445265297\n",
      "  Repetition 5/5\n",
      "    MAE: 15.338586807250977, RMSE: 20.5847492837822\n",
      "  Average MAE: 14.274957847595214 (±2.199152477495475), Average RMSE: 20.71662572022103 (±2.5361609033441446)\n",
      "\n",
      "Testing combination: LR=0.001, Layers=2, Heads=4, FF=256\n",
      "  Repetition 1/5\n",
      "    MAE: 23.02699851989746, RMSE: 46.603623304182314\n",
      "  Repetition 2/5\n",
      "    MAE: 5.551448345184326, RMSE: 7.777112481258232\n",
      "  Repetition 3/5\n",
      "    MAE: 10.877758979797363, RMSE: 13.564314619748233\n",
      "  Repetition 4/5\n",
      "    MAE: 6.586091995239258, RMSE: 7.59921532645844\n",
      "  Repetition 5/5\n",
      "    MAE: 7.802636623382568, RMSE: 9.588740628381753\n",
      "  Average MAE: 10.768986892700195 (±6.384187224036186), Average RMSE: 17.026601272005795 (±14.943480724146543)\n",
      "\n",
      "Testing combination: LR=0.001, Layers=2, Heads=4, FF=512\n",
      "  Repetition 1/5\n",
      "    MAE: 5.891389846801758, RMSE: 7.757049799649238\n",
      "  Repetition 2/5\n",
      "    MAE: 11.304007530212402, RMSE: 18.53580782903729\n",
      "  Repetition 3/5\n",
      "    MAE: 6.015486717224121, RMSE: 8.291328257135772\n",
      "  Repetition 4/5\n",
      "    MAE: 14.889840126037598, RMSE: 23.462131587993955\n",
      "  Repetition 5/5\n",
      "    MAE: 17.800073623657227, RMSE: 38.70132716857879\n",
      "  Average MAE: 11.180159568786621 (±4.738043078827359), Average RMSE: 19.34952892847901 (±11.390672607254631)\n",
      "\n",
      "Testing combination: LR=0.001, Layers=2, Heads=8, FF=256\n",
      "  Repetition 1/5\n",
      "    MAE: 7.956530570983887, RMSE: 8.623677912569908\n",
      "  Repetition 2/5\n",
      "    MAE: 4.289851665496826, RMSE: 7.973611224040738\n",
      "  Repetition 3/5\n",
      "    MAE: 13.323775291442871, RMSE: 18.22119877946941\n",
      "  Repetition 4/5\n",
      "    MAE: 12.606799125671387, RMSE: 19.779904673841326\n",
      "  Repetition 5/5\n",
      "    MAE: 13.071858406066895, RMSE: 17.2608298983362\n",
      "  Average MAE: 10.249763011932373 (±3.5706820478792634), Average RMSE: 14.371844497651518 (±5.027716937437867)\n",
      "\n",
      "Testing combination: LR=0.001, Layers=2, Heads=8, FF=512\n",
      "  Repetition 1/5\n",
      "    MAE: 14.982413291931152, RMSE: 25.2330458725043\n",
      "  Repetition 2/5\n",
      "    MAE: 14.797677040100098, RMSE: 43.71819854235834\n",
      "  Repetition 3/5\n",
      "    MAE: 5.598404884338379, RMSE: 6.483036500596492\n",
      "  Repetition 4/5\n",
      "    MAE: 11.431941986083984, RMSE: 16.706860002483356\n",
      "  Repetition 5/5\n",
      "    MAE: 4.385180473327637, RMSE: 5.325626089335244\n",
      "  Average MAE: 10.23912353515625 (±4.483457206179522), Average RMSE: 19.493353401455543 (±14.12476251323773)\n",
      "\n",
      "Testing combination: LR=0.001, Layers=3, Heads=4, FF=256\n",
      "  Repetition 1/5\n",
      "    MAE: 17.501848220825195, RMSE: 39.09133467009105\n",
      "  Repetition 2/5\n",
      "    MAE: 7.2658162117004395, RMSE: 11.650565962898943\n",
      "  Repetition 3/5\n",
      "    MAE: 13.981677055358887, RMSE: 25.880414165973924\n",
      "  Repetition 4/5\n",
      "    MAE: 9.985640525817871, RMSE: 14.615225892228262\n",
      "  Repetition 5/5\n",
      "    MAE: 10.740320205688477, RMSE: 13.082678582073166\n",
      "  Average MAE: 11.895060443878174 (±3.527017143745134), Average RMSE: 20.86404385465307 (±10.410414476528095)\n",
      "\n",
      "Testing combination: LR=0.001, Layers=3, Heads=4, FF=512\n",
      "  Repetition 1/5\n",
      "    MAE: 7.808406352996826, RMSE: 10.305237218207797\n",
      "  Repetition 2/5\n",
      "    MAE: 20.753223419189453, RMSE: 43.81081571076014\n",
      "  Repetition 3/5\n",
      "    MAE: 8.617928504943848, RMSE: 15.39985198903482\n",
      "  Repetition 4/5\n",
      "    MAE: 16.36228370666504, RMSE: 34.93519041449288\n",
      "  Repetition 5/5\n",
      "    MAE: 10.279626846313477, RMSE: 12.663328701365534\n",
      "  Average MAE: 12.764293766021728 (±4.993901545825221), Average RMSE: 23.42288480677223 (±13.41946860638675)\n",
      "\n",
      "Testing combination: LR=0.001, Layers=3, Heads=8, FF=256\n",
      "  Repetition 1/5\n",
      "    MAE: 4.4096150398254395, RMSE: 5.808405264468776\n",
      "  Repetition 2/5\n",
      "    MAE: 5.057145118713379, RMSE: 5.844041133707131\n",
      "  Repetition 3/5\n",
      "    MAE: 13.653153419494629, RMSE: 18.2210463684641\n",
      "  Repetition 4/5\n",
      "    MAE: 5.5653767585754395, RMSE: 7.685324508377787\n",
      "  Repetition 5/5\n",
      "    MAE: 12.378043174743652, RMSE: 31.732669936653515\n",
      "  Average MAE: 8.212666702270507 (±3.959240314384441), Average RMSE: 13.858297442334262 (±10.056454975358987)\n",
      "\n",
      "Testing combination: LR=0.001, Layers=3, Heads=8, FF=512\n",
      "  Repetition 1/5\n",
      "    MAE: 17.671810150146484, RMSE: 29.332021626130395\n",
      "  Repetition 2/5\n",
      "    MAE: 7.444689750671387, RMSE: 11.076441024822332\n",
      "  Repetition 3/5\n",
      "    MAE: 8.452343940734863, RMSE: 12.566162182895617\n",
      "  Repetition 4/5\n",
      "    MAE: 7.416426658630371, RMSE: 8.61817108932079\n",
      "  Repetition 5/5\n",
      "    MAE: 10.022424697875977, RMSE: 13.095329535359102\n",
      "  Average MAE: 10.201539039611816 (±3.8536679899251043), Average RMSE: 14.937625091705646 (±7.362890493843661)\n",
      "\n",
      "Testing combination: LR=0.001, Layers=4, Heads=4, FF=256\n",
      "  Repetition 1/5\n",
      "    MAE: 11.462479591369629, RMSE: 19.0946634077246\n",
      "  Repetition 2/5\n",
      "    MAE: 16.262468338012695, RMSE: 30.354290216875643\n",
      "  Repetition 3/5\n",
      "    MAE: 13.241060256958008, RMSE: 26.766643159633528\n",
      "  Repetition 4/5\n",
      "    MAE: 47.03229904174805, RMSE: 59.44405934495263\n",
      "  Repetition 5/5\n",
      "    MAE: 5.241434574127197, RMSE: 7.309027474937725\n",
      "  Average MAE: 18.647948360443117 (±14.642143906097415), Average RMSE: 28.593736720824825 (±17.328886098051314)\n",
      "\n",
      "Testing combination: LR=0.001, Layers=4, Heads=4, FF=512\n",
      "  Repetition 1/5\n",
      "    MAE: 11.768339157104492, RMSE: 16.008616034920557\n",
      "  Repetition 2/5\n",
      "    MAE: 11.609769821166992, RMSE: 14.537537492226482\n",
      "  Repetition 3/5\n",
      "    MAE: 7.6509318351745605, RMSE: 8.944953851298255\n",
      "  Repetition 4/5\n",
      "    MAE: 24.946638107299805, RMSE: 31.937146448018606\n",
      "  Repetition 5/5\n",
      "    MAE: 15.380024909973145, RMSE: 24.90061911920126\n",
      "  Average MAE: 14.271140766143798 (±5.871455441645222), Average RMSE: 19.26577458913303 (±8.146162117937013)\n",
      "\n",
      "Testing combination: LR=0.001, Layers=4, Heads=8, FF=256\n",
      "  Repetition 1/5\n",
      "    MAE: 6.369649410247803, RMSE: 11.717900359824426\n",
      "  Repetition 2/5\n",
      "    MAE: 7.4236531257629395, RMSE: 10.401277287615555\n",
      "  Repetition 3/5\n",
      "    MAE: 9.342159271240234, RMSE: 13.379014027850554\n",
      "  Repetition 4/5\n",
      "    MAE: 14.260262489318848, RMSE: 26.52147452235346\n",
      "  Repetition 5/5\n",
      "    MAE: 7.6947021484375, RMSE: 14.579344343767337\n",
      "  Average MAE: 9.018085289001466 (±2.7890218790557952), Average RMSE: 15.319802108282266 (±5.778546245612265)\n",
      "\n",
      "Testing combination: LR=0.001, Layers=4, Heads=8, FF=512\n",
      "  Repetition 1/5\n",
      "    MAE: 15.177226066589355, RMSE: 31.477928542894347\n",
      "  Repetition 2/5\n",
      "    MAE: 12.413606643676758, RMSE: 15.735662322431361\n",
      "  Repetition 3/5\n",
      "    MAE: 9.859879493713379, RMSE: 17.323242380181025\n",
      "  Repetition 4/5\n",
      "    MAE: 27.819677352905273, RMSE: 41.23363637316854\n",
      "  Repetition 5/5\n",
      "    MAE: 27.5052490234375, RMSE: 35.70403616178691\n",
      "  Average MAE: 18.555127716064455 (±7.624596955571994), Average RMSE: 28.294901156092436 (±10.104945227672616)\n",
      "\n",
      "Testing combination: LR=0.005, Layers=2, Heads=4, FF=256\n",
      "  Repetition 1/5\n",
      "    MAE: 46.18125534057617, RMSE: 58.61820323073712\n",
      "  Repetition 2/5\n",
      "    MAE: 56.825923919677734, RMSE: 68.37002595596077\n",
      "  Repetition 3/5\n",
      "    MAE: 51.15854263305664, RMSE: 61.17950543086815\n",
      "  Repetition 4/5\n",
      "    MAE: 47.3598518371582, RMSE: 59.39996391320979\n",
      "  Repetition 5/5\n",
      "    MAE: 50.173133850097656, RMSE: 61.3731164584961\n",
      "  Average MAE: 50.33974151611328 (±3.713260166664013), Average RMSE: 61.788162997854386 (±3.45299254143461)\n",
      "\n",
      "Testing combination: LR=0.005, Layers=2, Heads=4, FF=512\n",
      "  Repetition 1/5\n",
      "    MAE: 47.34063720703125, RMSE: 57.368144504648654\n",
      "  Repetition 2/5\n",
      "    MAE: 46.14329147338867, RMSE: 58.79883691584596\n",
      "  Repetition 3/5\n",
      "    MAE: 48.889381408691406, RMSE: 60.041178496381754\n",
      "  Repetition 4/5\n",
      "    MAE: 44.97240447998047, RMSE: 57.58650931153494\n",
      "  Repetition 5/5\n",
      "    MAE: 50.406776428222656, RMSE: 60.908693110954\n",
      "  Average MAE: 47.55049819946289 (±1.929858709881565), Average RMSE: 58.94067246787306 (±1.371928434234223)\n",
      "\n",
      "Testing combination: LR=0.005, Layers=2, Heads=8, FF=256\n",
      "  Repetition 1/5\n",
      "    MAE: 44.28931427001953, RMSE: 56.564459565503675\n",
      "  Repetition 2/5\n",
      "    MAE: 48.75102996826172, RMSE: 59.897424118367766\n",
      "  Repetition 3/5\n",
      "    MAE: 52.732601165771484, RMSE: 66.31760995863014\n",
      "  Repetition 4/5\n",
      "    MAE: 46.44770812988281, RMSE: 58.88427350333555\n",
      "  Repetition 5/5\n",
      "    MAE: 47.970130920410156, RMSE: 58.802488603932616\n",
      "  Average MAE: 48.03815689086914 (±2.797640822711627), Average RMSE: 60.09325114995395 (±3.2973036181755027)\n",
      "\n",
      "Testing combination: LR=0.005, Layers=2, Heads=8, FF=512\n",
      "  Repetition 1/5\n",
      "    MAE: 46.83732604980469, RMSE: 58.038176501684\n",
      "  Repetition 2/5\n",
      "    MAE: 45.899593353271484, RMSE: 58.81034757950233\n",
      "  Repetition 3/5\n",
      "    MAE: 47.987545013427734, RMSE: 59.48983344406946\n",
      "  Repetition 4/5\n",
      "    MAE: 47.1547737121582, RMSE: 58.53426772452932\n",
      "  Repetition 5/5\n",
      "    MAE: 47.04907989501953, RMSE: 59.131024237228885\n",
      "  Average MAE: 46.98566360473633 (±0.6690200045898486), Average RMSE: 58.8007298974028 (±0.49730077813199086)\n",
      "\n",
      "Testing combination: LR=0.005, Layers=3, Heads=4, FF=256\n",
      "  Repetition 1/5\n",
      "    MAE: 47.98216247558594, RMSE: 59.73240293958966\n",
      "  Repetition 2/5\n",
      "    MAE: 65.84960174560547, RMSE: 76.07338985828915\n",
      "  Repetition 3/5\n",
      "    MAE: 49.11039733886719, RMSE: 60.02616006857448\n",
      "  Repetition 4/5\n",
      "    MAE: 51.2388916015625, RMSE: 62.298528790438745\n",
      "  Repetition 5/5\n",
      "    MAE: 49.61282730102539, RMSE: 60.88759775641403\n",
      "  Average MAE: 52.758776092529295 (±6.628777626676358), Average RMSE: 63.80361588266121 (±6.19935076497506)\n",
      "\n",
      "Testing combination: LR=0.005, Layers=3, Heads=4, FF=512\n",
      "  Repetition 1/5\n",
      "    MAE: 67.26486206054688, RMSE: 77.72700498981997\n",
      "  Repetition 2/5\n",
      "    MAE: 50.217994689941406, RMSE: 60.50733789758995\n",
      "  Repetition 3/5\n",
      "    MAE: 68.08505249023438, RMSE: 78.62118681134876\n",
      "  Repetition 4/5\n",
      "    MAE: 67.65013122558594, RMSE: 78.11652766560512\n",
      "  Repetition 5/5\n",
      "    MAE: 67.77117156982422, RMSE: 78.24177834703305\n",
      "  Average MAE: 64.19784240722656 (±6.994857158962057), Average RMSE: 74.64276714227938 (±7.073480047620407)\n",
      "\n",
      "Testing combination: LR=0.005, Layers=3, Heads=8, FF=256\n",
      "  Repetition 1/5\n",
      "    MAE: 68.05442810058594, RMSE: 78.5740935906597\n",
      "  Repetition 2/5\n",
      "    MAE: 51.13445281982422, RMSE: 63.30522115426677\n",
      "  Repetition 3/5\n",
      "    MAE: 45.302249908447266, RMSE: 57.748511885588876\n",
      "  Repetition 4/5\n",
      "    MAE: 67.42111206054688, RMSE: 77.84197797561576\n",
      "  Repetition 5/5\n",
      "    MAE: 52.14240646362305, RMSE: 62.263621360485246\n",
      "  Average MAE: 56.81092987060547 (±9.224526389276518), Average RMSE: 67.94668519332326 (±8.587220391484305)\n",
      "\n",
      "Testing combination: LR=0.005, Layers=3, Heads=8, FF=512\n",
      "  Repetition 1/5\n",
      "    MAE: 51.613521575927734, RMSE: 60.01284449104416\n",
      "  Repetition 2/5\n",
      "    MAE: 52.22447204589844, RMSE: 62.62788673798298\n",
      "  Repetition 3/5\n",
      "    MAE: 54.04248809814453, RMSE: 62.16407575483709\n",
      "  Repetition 4/5\n",
      "    MAE: 50.16097640991211, RMSE: 60.333610295174616\n",
      "  Repetition 5/5\n",
      "    MAE: 67.71238708496094, RMSE: 78.17407208835293\n",
      "  Average MAE: 55.15076904296875 (±6.403060186576747), Average RMSE: 64.66249787347836 (±6.830855547616788)\n",
      "\n",
      "Testing combination: LR=0.005, Layers=4, Heads=4, FF=256\n",
      "  Repetition 1/5\n",
      "    MAE: 67.839111328125, RMSE: 78.32443294959116\n",
      "  Repetition 2/5\n",
      "    MAE: 54.36379623413086, RMSE: 62.44616626855987\n",
      "  Repetition 3/5\n",
      "    MAE: 48.652061462402344, RMSE: 59.51803905251121\n",
      "  Repetition 4/5\n",
      "    MAE: 67.83191680908203, RMSE: 78.31216330733687\n",
      "  Repetition 5/5\n",
      "    MAE: 49.64706039428711, RMSE: 60.338583252395395\n",
      "  Average MAE: 57.66678924560547 (±8.524049338431094), Average RMSE: 67.78787696607891 (±8.650961612582412)\n",
      "\n",
      "Testing combination: LR=0.005, Layers=4, Heads=4, FF=512\n",
      "  Repetition 1/5\n",
      "    MAE: 68.42045593261719, RMSE: 78.99506758731839\n",
      "  Repetition 2/5\n",
      "    MAE: 67.95712280273438, RMSE: 78.45720307813522\n",
      "  Repetition 3/5\n",
      "    MAE: 68.39146423339844, RMSE: 78.96130505071773\n",
      "  Repetition 4/5\n",
      "    MAE: 66.85353088378906, RMSE: 77.21328643156241\n",
      "  Repetition 5/5\n",
      "    MAE: 67.30333709716797, RMSE: 77.70390891671731\n",
      "  Average MAE: 67.78518218994141 (±0.6165813925775835), Average RMSE: 78.2661542128902 (±0.703661765579267)\n",
      "\n",
      "Testing combination: LR=0.005, Layers=4, Heads=8, FF=256\n",
      "  Repetition 1/5\n",
      "    MAE: 67.44023132324219, RMSE: 77.86093184024482\n",
      "  Repetition 2/5\n",
      "    MAE: 67.41781616210938, RMSE: 77.8351937288814\n",
      "  Repetition 3/5\n",
      "    MAE: 67.49373626708984, RMSE: 77.92266924850881\n",
      "  Repetition 4/5\n",
      "    MAE: 67.47361755371094, RMSE: 77.89923629680204\n",
      "  Repetition 5/5\n",
      "    MAE: 67.61104583740234, RMSE: 78.05725500293839\n",
      "  Average MAE: 67.48728942871094 (±0.06720882478647207), Average RMSE: 77.91505722347509 (±0.0772478970700698)\n",
      "\n",
      "Testing combination: LR=0.005, Layers=4, Heads=8, FF=512\n",
      "  Repetition 1/5\n",
      "    MAE: 67.45499420166016, RMSE: 77.87783715237121\n",
      "  Repetition 2/5\n",
      "    MAE: 68.32897186279297, RMSE: 78.8887944801494\n",
      "  Repetition 3/5\n",
      "    MAE: 67.88893127441406, RMSE: 78.37788758137559\n",
      "  Repetition 4/5\n",
      "    MAE: 67.58226013183594, RMSE: 78.0241317588267\n",
      "  Repetition 5/5\n",
      "    MAE: 67.81321716308594, RMSE: 78.29038432236585\n",
      "  Average MAE: 67.81367492675781 (±0.3011309780021549), Average RMSE: 78.29180705901776 (±0.34837537554761494)\n",
      "\n",
      "Best Hyperparameters: {'learning_rate': 0.001, 'num_layers': 3, 'nhead': 8, 'dim_feedforward': 256}\n",
      "Best Average MAE: 8.212666702270507\n",
      "Best Average RMSE: 13.858297442334262\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "from itertools import product\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "\n",
    "# Definindo constantes\n",
    "DATA_DIR = \"../../data/\"\n",
    "FILE_PATH = os.path.join(DATA_DIR, 'ts.pkl')\n",
    "SEQ_LENGTH = 120  # Aumentado para capturar mais contexto\n",
    "MB = 1_048_576\n",
    "\n",
    "# 1. Carregar e reamostrar os dados\n",
    "df = pd.read_pickle(FILE_PATH)\n",
    "ts = df['value'].astype(float).resample('15min').mean().dropna()  # Testando 15min\n",
    "dates = ts.index\n",
    "\n",
    "# 2. Dividir os dados: 60% treino, 20% validação, 20% teste\n",
    "train_size = int(0.6 * len(ts))\n",
    "val_size = int(0.2 * len(ts))\n",
    "train = ts[:train_size]\n",
    "val = ts[train_size:train_size + val_size]\n",
    "test = ts[train_size + val_size:]\n",
    "\n",
    "# 3. Escalonar os dados\n",
    "scaler = StandardScaler()\n",
    "train_scaled = scaler.fit_transform(train.values.reshape(-1, 1))\n",
    "val_scaled = scaler.transform(val.values.reshape(-1, 1))\n",
    "test_scaled = scaler.transform(test.values.reshape(-1, 1))\n",
    "\n",
    "# 4. Criar sequências\n",
    "def create_sequences(data, dates, seq_length):\n",
    "    X, y, y_dates = [], [], []\n",
    "    for i in range(len(data) - seq_length):\n",
    "        X.append(data[i:i + seq_length])\n",
    "        y.append(data[i + seq_length])\n",
    "        y_dates.append(dates[i + seq_length])\n",
    "    return np.array(X), np.array(y), np.array(y_dates)\n",
    "\n",
    "X_train, y_train, y_dates_train = create_sequences(train_scaled, dates[:train_size], SEQ_LENGTH)\n",
    "X_val, y_val, y_dates_val = create_sequences(val_scaled, dates[train_size:train_size + val_size], SEQ_LENGTH)\n",
    "X_test, y_test, y_dates_test = create_sequences(test_scaled, dates[train_size + val_size:], SEQ_LENGTH)\n",
    "\n",
    "# 5. Ajustar dimensões para o modelo Transformer\n",
    "d_model = 128  # Aumentado para representações mais ricas\n",
    "X_train = np.repeat(X_train, d_model, axis=2)\n",
    "X_val = np.repeat(X_val, d_model, axis=2)\n",
    "X_test = np.repeat(X_test, d_model, axis=2)\n",
    "\n",
    "# 6. Converter para tensores PyTorch\n",
    "X_train = torch.tensor(X_train, dtype=torch.float32)\n",
    "y_train = torch.tensor(y_train, dtype=torch.float32)\n",
    "X_val = torch.tensor(X_val, dtype=torch.float32)\n",
    "y_val = torch.tensor(y_val, dtype=torch.float32)\n",
    "X_test = torch.tensor(X_test, dtype=torch.float32)\n",
    "y_test = torch.tensor(y_test, dtype=torch.float32)\n",
    "\n",
    "# 7. Definir codificação posicional\n",
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model, max_len=5000):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-np.log(10000.0) / d_model))\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        pe = pe.unsqueeze(0)\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x + self.pe[:, :x.size(1), :]\n",
    "        return x\n",
    "\n",
    "# 8. Definir o modelo Transformer\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, input_dim, d_model, nhead, num_layers, dim_feedforward, dropout=0.1):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.pos_encoder = PositionalEncoding(d_model)\n",
    "        self.encoder_layer = nn.TransformerEncoderLayer(\n",
    "            d_model=d_model, nhead=nhead, dim_feedforward=dim_feedforward, dropout=dropout, batch_first=True\n",
    "        )\n",
    "        self.transformer_encoder = nn.TransformerEncoder(self.encoder_layer, num_layers=num_layers)\n",
    "        self.linear_out = nn.Linear(d_model, 1)\n",
    "\n",
    "    def forward(self, src):\n",
    "        src = self.pos_encoder(src)\n",
    "        output = self.transformer_encoder(src)\n",
    "        output = self.linear_out(output[:, -1, :])  # Pegar apenas o último timestep\n",
    "        return output\n",
    "\n",
    "# Hiperparâmetros para tuning\n",
    "learning_rates = [0.0001, 0.001, 0.005]\n",
    "num_layers_list = [2, 3, 4]\n",
    "nheads = [4, 8]\n",
    "dim_feedforwards = [256, 512]\n",
    "\n",
    "# Outros hiperparâmetros fixos\n",
    "input_dim = d_model\n",
    "batch_size = 32  # Reduzido para maior estabilidade\n",
    "num_epochs = 50  # Aumentado com parada precoce\n",
    "\n",
    "# Função de treinamento\n",
    "def train_model(learning_rate, num_layers, nhead, dim_feedforward):\n",
    "    model = Encoder(input_dim, d_model, nhead, num_layers, dim_feedforward)\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', patience=5, factor=0.5)\n",
    "\n",
    "    best_val_loss = float('inf')\n",
    "    patience = 10\n",
    "    patience_counter = 0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        for i in range(0, len(X_train), batch_size):\n",
    "            X_batch = X_train[i:i + batch_size]\n",
    "            y_batch = y_train[i:i + batch_size]\n",
    "            outputs = model(X_batch)\n",
    "            loss = criterion(outputs, y_batch)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        # Validação\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            y_val_pred = model(X_val)\n",
    "            val_loss = criterion(y_val_pred, y_val)\n",
    "        \n",
    "        scheduler.step(val_loss)\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            patience_counter = 0\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "            if patience_counter >= patience:\n",
    "                break\n",
    "\n",
    "    return model\n",
    "\n",
    "# Grid search com repetições\n",
    "best_avg_mae = float('inf')\n",
    "best_avg_rmse = float('inf')\n",
    "best_hyperparams = None\n",
    "best_model = None\n",
    "n_repetitions = 5\n",
    "\n",
    "for lr, nl, nh, df in product(learning_rates, num_layers_list, nheads, dim_feedforwards):\n",
    "    mae_list = []\n",
    "    rmse_list = []\n",
    "    \n",
    "    print(f\"\\nTesting combination: LR={lr}, Layers={nl}, Heads={nh}, FF={df}\")\n",
    "    for rep in range(n_repetitions):\n",
    "        print(f\"  Repetition {rep+1}/{n_repetitions}\")\n",
    "        model = train_model(lr, nl, nh, df)\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            y_pred = model(X_test)\n",
    "        \n",
    "        y_pred_rescaled = scaler.inverse_transform(y_pred.numpy()) / MB\n",
    "        y_test_rescaled = scaler.inverse_transform(y_test.numpy()) / MB\n",
    "        \n",
    "        mae = mean_absolute_error(y_test_rescaled, y_pred_rescaled)\n",
    "        rmse = np.sqrt(mean_squared_error(y_test_rescaled, y_pred_rescaled))\n",
    "        \n",
    "        mae_list.append(mae)\n",
    "        rmse_list.append(rmse)\n",
    "        print(f\"    MAE: {mae}, RMSE: {rmse}\")\n",
    "    \n",
    "    # Calcular médias\n",
    "    avg_mae = np.mean(mae_list)\n",
    "    avg_rmse = np.mean(rmse_list)\n",
    "    std_mae = np.std(mae_list)\n",
    "    std_rmse = np.std(rmse_list)\n",
    "    \n",
    "    print(f\"  Average MAE: {avg_mae} (±{std_mae}), Average RMSE: {avg_rmse} (±{std_rmse})\")\n",
    "    \n",
    "    if avg_mae < best_avg_mae:\n",
    "        best_avg_mae = avg_mae\n",
    "        best_avg_rmse = avg_rmse\n",
    "        best_hyperparams = {'learning_rate': lr, 'num_layers': nl, 'nhead': nh, 'dim_feedforward': df}\n",
    "        best_model = model\n",
    "\n",
    "print(f'\\nBest Hyperparameters: {best_hyperparams}')\n",
    "print(f'Best Average MAE: {best_avg_mae}')\n",
    "print(f'Best Average RMSE: {best_avg_rmse}')\n",
    "\n",
    "# 9. Fazer previsões\n",
    "model = best_model\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    y_train_pred = model(X_train)\n",
    "    y_test_pred = model(X_test)\n",
    "\n",
    "# 10. Reverter o escalonamento e converter para MB\n",
    "y_train_pred_mb = scaler.inverse_transform(y_train_pred.numpy()) / MB\n",
    "y_train_mb = scaler.inverse_transform(y_train.numpy()) / MB\n",
    "y_test_pred_mb = scaler.inverse_transform(y_test_pred.numpy()) / MB\n",
    "y_test_mb = scaler.inverse_transform(y_test.numpy()) / MB\n",
    "\n",
    "# 11. Preparar dados para plotagem\n",
    "train_df = pd.DataFrame({\n",
    "    'date': y_dates_train,\n",
    "    'actual': y_train_mb.flatten(),\n",
    "    'predicted': y_train_pred_mb.flatten()\n",
    "}).sort_values('date')\n",
    "\n",
    "test_df = pd.DataFrame({\n",
    "    'date': y_dates_test,\n",
    "    'actual': y_test_mb.flatten(),\n",
    "    'predicted': y_test_pred_mb.flatten()\n",
    "}).sort_values('date')\n",
    "\n",
    "# 12. Plotar os resultados\n",
    "plt.style.use('default')\n",
    "fig, axs = plt.subplots(2, 1, figsize=(15, 10), sharex=False)\n",
    "\n",
    "axs[0].plot(train_df['date'], train_df['actual'], label='Real', color='blue', linewidth=1.5)\n",
    "axs[0].plot(train_df['date'], train_df['predicted'], label='Predito', color='red', alpha=0.7, linewidth=1.5)\n",
    "axs[0].set_title('Conjunto de Treinamento (60%)', fontsize=12, pad=10)\n",
    "axs[0].set_ylabel('Consumo de Memória (MB)', fontsize=10)\n",
    "axs[0].legend(loc='upper left', fontsize=10)\n",
    "axs[0].grid(True, linestyle='--', alpha=0.7)\n",
    "\n",
    "axs[1].plot(test_df['date'], test_df['actual'], label='Real', color='blue', linewidth=1.5)\n",
    "axs[1].plot(test_df['date'], test_df['predicted'], label='Predito', color='red', alpha=0.7, linewidth=1.5)\n",
    "axs[1].set_title('Conjunto de Teste (20%)', fontsize=12, pad=10)\n",
    "axs[1].set_xlabel('Data', fontsize=10)\n",
    "axs[1].set_ylabel('Consumo de Memória (MB)', fontsize=10)\n",
    "axs[1].legend(loc='upper left', fontsize=10)\n",
    "axs[1].grid(True, linestyle='--', alpha=0.7)\n",
    "\n",
    "for ax in axs:\n",
    "    ax.xaxis.set_major_locator(mdates.AutoDateLocator())\n",
    "    ax.xaxis.set_major_formatter(mdates.DateFormatter('%Y-%m-%d'))\n",
    "    ax.tick_params(axis='x', rotation=45, labelsize=9)\n",
    "    ax.tick_params(axis='y', labelsize=9)\n",
    "\n",
    "plt.suptitle('Predições do Transformer Otimizado - Prometheus (MB, Resample 15min)', fontsize=14, y=0.98)\n",
    "plt.tight_layout(rect=[0, 0, 1, 0.95])\n",
    "plt.savefig(os.path.join(DATA_DIR, 'prometheus_transformer_robust_15min.png'), dpi=300, bbox_inches='tight')\n",
    "plt.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
